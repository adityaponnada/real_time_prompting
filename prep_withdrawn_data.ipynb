{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502a0dd7",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b5f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cb9aa",
   "metadata": {},
   "source": [
    "## Read the withdrawn participant file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d440ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Record ID            Visualizer ID Participant Status  Consent Date  \\\n",
      "0       9001       sharpnessnextpouch           Completed    3/17/2020   \n",
      "1       9002     uniformlyharmfulbush          Unenrolled    3/18/2020   \n",
      "2       9003     hacksawscoldingdares            Withdrew    3/27/2020   \n",
      "3       9004    dimnesscranialunheard           Completed    3/28/2020   \n",
      "4       9005  coynessculminatebarista           Completed     4/8/2020   \n",
      "\n",
      "  Date participant completed Date participant withdrew  \\\n",
      "0                  3/17/2021                       NaN   \n",
      "1                        NaN                       NaN   \n",
      "2                        NaN                 12/4/2020   \n",
      "3                  3/28/2021                       NaN   \n",
      "4                   4/8/2021                       NaN   \n",
      "\n",
      "  Date participant unenrolled Date Devices Mailed ID of device loaned  \\\n",
      "0                         NaN           3/25/2020        C2F9214C2188   \n",
      "1                  10/20/2020           3/25/2020        C2F9202C1141   \n",
      "2                         NaN            4/7/2020        C2F9153C0327   \n",
      "3                         NaN            4/7/2020        C2F9151C0324   \n",
      "4                         NaN           4/14/2020        C2F9262C1610   \n",
      "\n",
      "  Watch training date  Exit Interview Date  \n",
      "0            3/28/2020           3/19/2021  \n",
      "1            3/28/2020                 NaN  \n",
      "2            4/10/2020                 NaN  \n",
      "3            4/13/2020                 NaN  \n",
      "4            4/20/2020                 NaN  \n",
      "Index(['Record ID', 'Visualizer ID', 'Participant Status ', 'Consent Date',\n",
      "       'Date participant completed', 'Date participant withdrew',\n",
      "       'Date participant unenrolled', 'Date Devices Mailed',\n",
      "       'ID of device loaned', 'Watch training date ', 'Exit Interview Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Import the status file\n",
    "status_file = '/Users/adityaponnada/Downloads/time_study_data/participant_status_tracking_v2.csv'\n",
    "status_df = pd.read_csv(status_file)\n",
    "\n",
    "## Show the first few rows\n",
    "print(status_df.head())\n",
    "# Also print the columns names\n",
    "print(status_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8dab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             participant_id    status\n",
      "0        hacksawscoldingdares@timestudy_com  Withdrew\n",
      "1               altoironyahoo@timestudy_com  Withdrew\n",
      "2         wadblatancyflattery@timestudy_com  Withdrew\n",
      "3  breechingtamenessdreamboat@timestudy_com  Withdrew\n",
      "4        overstepsadnesscarat@timestudy_com  Withdrew\n",
      "(90, 2)\n"
     ]
    }
   ],
   "source": [
    "## Filter completed participants. We will only keep the visualizerID and status columns\n",
    "status_df = status_df[status_df['Participant Status '] == 'Withdrew'][['Visualizer ID', 'Participant Status ']]\n",
    "# Rename the visualizerID column to participant_id.\n",
    "status_df.rename(columns={'Visualizer ID': 'participant_id'}, inplace=True)\n",
    "# Also rename participant status to status\n",
    "status_df.rename(columns={'Participant Status ': 'status'}, inplace=True)\n",
    "# Reset the index\n",
    "status_df.reset_index(drop=True, inplace=True)\n",
    "# Add @timestudy_com to the participant_id column\n",
    "status_df['participant_id'] = status_df['participant_id'] + '@timestudy_com'\n",
    "## Show the first few rows\n",
    "print(status_df.head())\n",
    "# Also print the shape of the dataframe\n",
    "print(status_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d76342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hacksawscoldingdares@timestudy_com', 'altoironyahoo@timestudy_com', 'wadblatancyflattery@timestudy_com', 'breechingtamenessdreamboat@timestudy_com', 'overstepsadnesscarat@timestudy_com', 'smeltingexerciserstabilize@timestudy_com', 'shaftbribezippy@timestudy_com', 'splinterimmorallyupward@timestudy_com', 'rankingkindnessspindle@timestudy_com', 'musicvividlybackstage@timestudy_com', 'backyardscapegoatoverrun@timestudy_com', 'floggingnicknamecondone/uprisingdisdaingraveyard@timestudy_com', 'hurricaneshrubscoral@timestudy_com', 'riftchaosdipper@timestudy_com', 'dizzinesscatatoniceconomist@timestudy_com', 'skydiverworriercarton@timestudy_com', 'cladlandscapeheave@timestudy_com', 'unrelatedtweedconcerned@timestudy_com', 'anywaymustinesspushiness@timestudy_com', 'unafraidreproducewad@timestudy_com', 'shadilymanholegreeter@timestudy_com', 'palmbuggystole@timestudy_com', 'ambushdollhousegenerous@timestudy_com', 'skipperdropdowncrawlers@timestudy_com', 'itunesgurgleexchange@timestudy_com', 'generouswidthcoasting@timestudy_com', 'livedsciencelinguist@timestudy_com', 'spousalpessimismvariety@timestudy_com', 'pulmonarysadlygrunge@timestudy_com', 'deitymagnifierdrove@timestudy_com', 'unwrappedsnaggedepiphany@timestudy_com', 'sadnessvoweluniformly@timestudy_com', 'browsingfrisbeepersevere@timestudy_com', 'wikipediamoodinessomission@timestudy_com', 'unmoldedtrustfulencode@timestudy_com', 'colonialdemystifyduress@timestudy_com', 'lizardcauterizepreplan@timestudy_com', 'keennesstwiddlelinked@timestudy_com', 'ropetinworkdemote@timestudy_com', 'shadedfacebookcoke@timestudy_com', 'enjoyingretreathandled@timestudy_com', 'pamperedchlorideconflict@timestudy_com', 'aviationwinterreprise@timestudy_com', 'lappedvastlydebating@timestudy_com', 'strivezigzaggedgrappling@timestudy_com', 'huntingevergreendeparted@timestudy_com', 'phobiaaltogallows@timestudy_com', 'moonriseskintightjubilance@timestudy_com', 'confrontcaresssullen@timestudy_com', 'shorerecliningstoppage@timestudy_com', 'mumblingenteringstipulate@timestudy_com', 'liablevirtuousplaything@timestudy_com', 'sizzleunelectedmagical@timestudy_com', 'anacondahelplinehatless@timestudy_com', 'sinistersmolderthesis@timestudy_com', 'dimmeddismaylegume@timestudy_com', 'bulbdemocracydropper@timestudy_com', 'shadedechorogue@timestudy_com', 'hatlesslegacyeducated@timestudy_com', 'civicexcludingbarcode@timestudy_com', 'resampledistrustpulverize@timestudy_com', 'buckedstiflestagnant@timestudy_com', 'euphemismfederalconfusing@timestudy_com', 'multitaskdisprovealkalize@timestudy_com', 'busybodyestimatesensitize@timestudy_com', 'synthesisrebuffcognition@timestudy_com', 'iodinegrapemonstrous@timestudy_com', 'scoutsstaunchskating@timestudy_com', 'motivatorelectableflammable@timestudy_com', 'bottledeskworkrequire@timestudy_com', 'modifyjavamodule@timestudy_com', 'sterileshinejokingly@timestudy_com', 'oinkslicedcrop@timestudy_com', 'playablevividnessboxer@timestudy_com', 'gushyenstir@timestudy_com', 'hazingdiscolorsuffering@timestudy_com', 'scopelaboriousmagician@timestudy_com', 'atriumscribefiddle@timestudy_com', 'legalsaddledresemble@timestudy_com', 'ferretremovalwistful@timestudy_com', 'strikingemporiumripeness@timestudy_com', 'orbsquackysyllabuses@timestudy_com', 'crewmanfacingundusted@timestudy_com', 'uptakepassengerpope@timestudy_com', 'undertonemuskinesslullaby@timestudy_com', 'rentedmanordaunting@timestudy_com', 'unglazedshorterrepave@timestudy_com', 'omissionshreddercorrosive@timestudy_com', 'himationlalospheres@timestudy_com', 'metepaswevetbrasero@timestudy_com']\n"
     ]
    }
   ],
   "source": [
    "withdrew_ids = status_df['participant_id'].tolist()\n",
    "print(withdrew_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6568f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235112, 62)\n"
     ]
    }
   ],
   "source": [
    "def load_withdrew_comp_matrix(holdout_list, base_dir='/Users/adityaponnada/Downloads/time_study_data/compliance_matrix/'):\n",
    "    \"\"\"\n",
    "    For each folder in `base_dir` whose name is present in `holdout_list`,\n",
    "    concatenate all CSVs matching `uema_feature_mx_*.csv` in that folder (in sorted order)\n",
    "    and append them to a single dataframe. Process folders sequentially (sorted by name).\n",
    "    Returns a pandas DataFrame (does NOT add a `heldout_user` column).\n",
    "    \"\"\"\n",
    "    import os, glob\n",
    "    import pandas as pd\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise FileNotFoundError(f'Base directory not found: {base_dir}')\n",
    "    # Ensure holdout_list elements are strings for matching\n",
    "    holdout_set = set(str(x) for x in holdout_list)\n",
    "    # Find folders in base_dir that match heldout users\n",
    "    all_entries = sorted(os.listdir(base_dir))\n",
    "    matched_folders = [d for d in all_entries if os.path.isdir(os.path.join(base_dir, d)) and d in holdout_set]\n",
    "    matched_folders.sort()\n",
    "    out_frames = []\n",
    "    for folder in matched_folders:\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        pattern = os.path.join(folder_path, 'uema_feature_mx_*.csv')\n",
    "        files = sorted(glob.glob(pattern))\n",
    "        if not files:\n",
    "            # no matching files for this user; skip\n",
    "            continue\n",
    "        user_frames = []\n",
    "        for fp in files:\n",
    "            try:\n",
    "                df = pd.read_csv(fp)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to read {fp}: {e}')\n",
    "                continue\n",
    "            user_frames.append(df)\n",
    "        if user_frames:\n",
    "            user_df = pd.concat(user_frames, ignore_index=True)\n",
    "            # Do not add heldout_user column per request\n",
    "            out_frames.append(user_df)\n",
    "    if out_frames:\n",
    "        heldout_df = pd.concat(out_frames, ignore_index=True)\n",
    "    else:\n",
    "        heldout_df = pd.DataFrame()\n",
    "    return heldout_df\n",
    "\n",
    "# Example usage (run in a cell after `holdout_list` is defined):\n",
    "withdrew_df = load_withdrew_comp_matrix(withdrew_ids)\n",
    "print(withdrew_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "352f806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Initial_Prompt_Date</th>\n",
       "      <th>Prompt_Type</th>\n",
       "      <th>Study_Mode</th>\n",
       "      <th>Initial_Prompt_Local_Time</th>\n",
       "      <th>Answer_Status</th>\n",
       "      <th>Actual_Prompt_Local_Time</th>\n",
       "      <th>First_Question_Completion_Unixtime</th>\n",
       "      <th>UTC_Offset</th>\n",
       "      <th>Reprompt_Num</th>\n",
       "      <th>...</th>\n",
       "      <th>start_time_7min</th>\n",
       "      <th>mims_summary_8min</th>\n",
       "      <th>num_readings_8min</th>\n",
       "      <th>start_time_8min</th>\n",
       "      <th>mims_summary_9min</th>\n",
       "      <th>num_readings_9min</th>\n",
       "      <th>start_time_9min</th>\n",
       "      <th>mims_summary_10min</th>\n",
       "      <th>num_readings_10min</th>\n",
       "      <th>start_time_10min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambushdollhousegenerous@timestudy_com</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>Trivia_EMA_Micro</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Wed Nov 25 07:24:03 MST 2020</td>\n",
       "      <td>NeverStarted</td>\n",
       "      <td>Wed Nov 25 07:24:03 MST 2020</td>\n",
       "      <td>-1</td>\n",
       "      <td>GMT-07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-25 07:16:03.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2020-11-25 07:15:03.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2020-11-25 07:14:03.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2020-11-25 07:13:03.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambushdollhousegenerous@timestudy_com</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>Trivia_EMA_Micro</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Wed Nov 25 09:54:06 MST 2020</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Wed Nov 25 09:54:06 MST 2020</td>\n",
       "      <td>1606323255361</td>\n",
       "      <td>GMT-07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambushdollhousegenerous@timestudy_com</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>Trivia_EMA_Micro</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Wed Nov 25 15:37:13 MST 2020</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Wed Nov 25 15:37:13 MST 2020</td>\n",
       "      <td>1606343842226</td>\n",
       "      <td>GMT-07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambushdollhousegenerous@timestudy_com</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>Trivia_EMA_Micro</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Wed Nov 25 19:42:03 MST 2020</td>\n",
       "      <td>NeverStarted</td>\n",
       "      <td>Wed Nov 25 19:42:03 MST 2020</td>\n",
       "      <td>-1</td>\n",
       "      <td>GMT-07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ambushdollhousegenerous@timestudy_com</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>Trivia_EMA_Micro</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Wed Nov 25 20:38:25 MST 2020</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Wed Nov 25 20:38:25 MST 2020</td>\n",
       "      <td>1606361910588</td>\n",
       "      <td>GMT-07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Participant_ID Initial_Prompt_Date  \\\n",
       "0  ambushdollhousegenerous@timestudy_com          2020-11-25   \n",
       "1  ambushdollhousegenerous@timestudy_com          2020-11-25   \n",
       "2  ambushdollhousegenerous@timestudy_com          2020-11-25   \n",
       "3  ambushdollhousegenerous@timestudy_com          2020-11-25   \n",
       "4  ambushdollhousegenerous@timestudy_com          2020-11-25   \n",
       "\n",
       "        Prompt_Type Study_Mode     Initial_Prompt_Local_Time Answer_Status  \\\n",
       "0  Trivia_EMA_Micro       TIME  Wed Nov 25 07:24:03 MST 2020  NeverStarted   \n",
       "1  Trivia_EMA_Micro       TIME  Wed Nov 25 09:54:06 MST 2020     Completed   \n",
       "2  Trivia_EMA_Micro       TIME  Wed Nov 25 15:37:13 MST 2020     Completed   \n",
       "3  Trivia_EMA_Micro       TIME  Wed Nov 25 19:42:03 MST 2020  NeverStarted   \n",
       "4  Trivia_EMA_Micro       TIME  Wed Nov 25 20:38:25 MST 2020     Completed   \n",
       "\n",
       "       Actual_Prompt_Local_Time  First_Question_Completion_Unixtime  \\\n",
       "0  Wed Nov 25 07:24:03 MST 2020                                  -1   \n",
       "1  Wed Nov 25 09:54:06 MST 2020                       1606323255361   \n",
       "2  Wed Nov 25 15:37:13 MST 2020                       1606343842226   \n",
       "3  Wed Nov 25 19:42:03 MST 2020                                  -1   \n",
       "4  Wed Nov 25 20:38:25 MST 2020                       1606361910588   \n",
       "\n",
       "  UTC_Offset  Reprompt_Num  ...          start_time_7min mims_summary_8min  \\\n",
       "0  GMT-07:00             0  ...  2020-11-25 07:16:03.003               0.0   \n",
       "1  GMT-07:00             0  ...                      NaN                OB   \n",
       "2  GMT-07:00             0  ...                      NaN                OB   \n",
       "3  GMT-07:00             0  ...                      NaN                OB   \n",
       "4  GMT-07:00             0  ...                      NaN                OB   \n",
       "\n",
       "   num_readings_8min          start_time_8min mims_summary_9min  \\\n",
       "0              340.0  2020-11-25 07:15:03.003               0.0   \n",
       "1                0.0                      NaN                OB   \n",
       "2                0.0                      NaN                OB   \n",
       "3                0.0                      NaN                OB   \n",
       "4                0.0                      NaN                OB   \n",
       "\n",
       "  num_readings_9min          start_time_9min mims_summary_10min  \\\n",
       "0             400.0  2020-11-25 07:14:03.003                0.0   \n",
       "1               0.0                      NaN                 OB   \n",
       "2               0.0                      NaN                 OB   \n",
       "3               0.0                      NaN                 OB   \n",
       "4               0.0                      NaN                 OB   \n",
       "\n",
       "  num_readings_10min         start_time_10min  \n",
       "0              460.0  2020-11-25 07:13:03.003  \n",
       "1                0.0                      NaN  \n",
       "2                0.0                      NaN  \n",
       "3                0.0                      NaN  \n",
       "4                0.0                      NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withdrew_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46e4d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withdrew_df['Participant_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc5ff2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ambushdollhousegenerous@timestudy_com', 'unknown_user',\n",
       "       'anywaymustinesspushiness@timestudy_com',\n",
       "       'bottledeskworkrequire@timestudy_com',\n",
       "       'browsingfrisbeepersevere@timestudy_com',\n",
       "       'buckedstiflestagnant@timestudy_com',\n",
       "       'busybodyestimatesensitize@timestudy_com',\n",
       "       'civicexcludingbarcode@timestudy_com',\n",
       "       'cladlandscapeheave@timestudy_com',\n",
       "       'confrontcaresssullen@timestudy_com',\n",
       "       'deitymagnifierdrove@timestudy_com',\n",
       "       'dimmeddismaylegume@timestudy_com',\n",
       "       'dizzinesscatatoniceconomist@timestudy_com',\n",
       "       'enjoyingretreathandled@timestudy_com',\n",
       "       'euphemismfederalconfusing@timestudy_com',\n",
       "       'generouswidthcoasting@timestudy_com', 'gushyenstir@timestudy_com',\n",
       "       'hacksawscoldingdares@timestudy_com',\n",
       "       'hazingdiscolorsuffering@timestudy_com',\n",
       "       'himationlalospheres@timestudy_com',\n",
       "       'huntingevergreendeparted@timestudy_com',\n",
       "       'iodinegrapemonstrous@timestudy_com',\n",
       "       'itunesgurgleexchange@timestudy_com',\n",
       "       'lappedvastlydebating@timestudy_com',\n",
       "       'legalsaddledresemble@timestudy_com',\n",
       "       'liablevirtuousplaything@timestudy_com',\n",
       "       'livedsciencelinguist@timestudy_com',\n",
       "       'lizardcauterizepreplan@timestudy_com',\n",
       "       'metepaswevetbrasero@timestudy_com',\n",
       "       'modifyjavamodule@timestudy_com',\n",
       "       'multitaskdisprovealkalize@timestudy_com',\n",
       "       'musicvividlybackstage@timestudy_com',\n",
       "       'orbsquackysyllabuses@timestudy_com',\n",
       "       'palmbuggystole@timestudy_com',\n",
       "       'pamperedchlorideconflict@timestudy_com',\n",
       "       'phobiaaltogallows@timestudy_com',\n",
       "       'rankingkindnessspindle@timestudy_com',\n",
       "       'rentedmanordaunting@timestudy_com',\n",
       "       'resampledistrustpulverize@timestudy_com',\n",
       "       'riftchaosdipper@timestudy_com', 'ropetinworkdemote@timestudy_com',\n",
       "       'sadnessvoweluniformly@timestudy_com',\n",
       "       'scopelaboriousmagician@timestudy_com',\n",
       "       'scoutsstaunchskating@timestudy_com',\n",
       "       'shadedfacebookcoke@timestudy_com',\n",
       "       'shadilymanholegreeter@timestudy_com',\n",
       "       'shorerecliningstoppage@timestudy_com',\n",
       "       'sinistersmolderthesis@timestudy_com',\n",
       "       'sizzleunelectedmagical@timestudy_com',\n",
       "       'skipperdropdowncrawlers@timestudy_com',\n",
       "       'skydiverworriercarton@timestudy_com',\n",
       "       'smeltingexerciserstabilize@timestudy_com',\n",
       "       'splinterimmorallyupward@timestudy_com',\n",
       "       'spousalpessimismvariety@timestudy_com',\n",
       "       'sterileshinejokingly@timestudy_com',\n",
       "       'strikingemporiumripeness@timestudy_com',\n",
       "       'unafraidreproducewad@timestudy_com',\n",
       "       'unmoldedtrustfulencode@timestudy_com',\n",
       "       'unwrappedsnaggedepiphany@timestudy_com'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withdrew_df['Participant_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2270f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235071, 62)\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "## Remove Participant_ID. = 'unknown_user'\n",
    "withdrew_df = withdrew_df[withdrew_df['Participant_ID'] != 'unknown_user']\n",
    "print(withdrew_df.shape)\n",
    "print(withdrew_df['Participant_ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a3a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Withdrew dataframe saved to /Users/adityaponnada/Downloads/time_study_data/withdrew_comp_mx_20260122_000325.csv\n"
     ]
    }
   ],
   "source": [
    "## Save compliance_matrix to a csv file. The filename should have _date_time appended to it.\n",
    "import datetime\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "withdrew_df.to_csv(f'/Users/adityaponnada/Downloads/time_study_data/withdrew_comp_mx_{current_time}.csv', index=False)\n",
    "print(f\"Withdrew dataframe saved to /Users/adityaponnada/Downloads/time_study_data/withdrew_comp_mx_{current_time}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
