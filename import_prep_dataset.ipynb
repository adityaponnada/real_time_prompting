{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910898c2",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "This notebook imports participant data from TIME study, keeps only those who completed the study, comutes all the features, then saves two files:\n",
    "1. Feature set for all the users\n",
    "2. A sample of users to try different ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93d803",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "Import essential libraries here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c3fd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797cc3d",
   "metadata": {},
   "source": [
    "## Import participant status\n",
    "We will import participant status data. So that we can filter out those who completed the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2aa2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Record ID            Visualizer ID Participant Status  Consent Date  \\\n",
      "0       9001       sharpnessnextpouch           Completed    3/17/2020   \n",
      "1       9002     uniformlyharmfulbush          Unenrolled    3/18/2020   \n",
      "2       9003     hacksawscoldingdares            Withdrew    3/27/2020   \n",
      "3       9004    dimnesscranialunheard           Completed    3/28/2020   \n",
      "4       9005  coynessculminatebarista           Completed     4/8/2020   \n",
      "\n",
      "  Date participant completed Date participant withdrew  \\\n",
      "0                  3/17/2021                       NaN   \n",
      "1                        NaN                       NaN   \n",
      "2                        NaN                 12/4/2020   \n",
      "3                  3/28/2021                       NaN   \n",
      "4                   4/8/2021                       NaN   \n",
      "\n",
      "  Date participant unenrolled Date Devices Mailed ID of device loaned  \\\n",
      "0                         NaN           3/25/2020        C2F9214C2188   \n",
      "1                  10/20/2020           3/25/2020        C2F9202C1141   \n",
      "2                         NaN            4/7/2020        C2F9153C0327   \n",
      "3                         NaN            4/7/2020        C2F9151C0324   \n",
      "4                         NaN           4/14/2020        C2F9262C1610   \n",
      "\n",
      "  Watch training date  Exit Interview Date  \n",
      "0            3/28/2020           3/19/2021  \n",
      "1            3/28/2020                 NaN  \n",
      "2            4/10/2020                 NaN  \n",
      "3            4/13/2020                 NaN  \n",
      "4            4/20/2020                 NaN  \n",
      "Index(['Record ID', 'Visualizer ID', 'Participant Status ', 'Consent Date',\n",
      "       'Date participant completed', 'Date participant withdrew',\n",
      "       'Date participant unenrolled', 'Date Devices Mailed',\n",
      "       'ID of device loaned', 'Watch training date ', 'Exit Interview Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Import the status file\n",
    "status_file = '/Users/adityaponnada/Downloads/time_study_data/participant_status_tracking_v2.csv'\n",
    "status_df = pd.read_csv(status_file)\n",
    "\n",
    "## Show the first few rows\n",
    "print(status_df.head())\n",
    "# Also print the columns names\n",
    "print(status_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02ca55",
   "metadata": {},
   "source": [
    "Now only keep the completed participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33ced38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           participant_id     status\n",
      "0        sharpnessnextpouch@timestudy_com  Completed\n",
      "1     dimnesscranialunheard@timestudy_com  Completed\n",
      "2   coynessculminatebarista@timestudy_com  Completed\n",
      "3  spinstersubatomiccoyness@timestudy_com  Completed\n",
      "4     sadlyskilledlustfully@timestudy_com  Completed\n",
      "(136, 2)\n"
     ]
    }
   ],
   "source": [
    "## Filter completed participants. We will only keep the visualizerID and status columns\n",
    "status_df = status_df[status_df['Participant Status '] == 'Completed'][['Visualizer ID', 'Participant Status ']]\n",
    "# Rename the visualizerID column to participant_id.\n",
    "status_df.rename(columns={'Visualizer ID': 'participant_id'}, inplace=True)\n",
    "# Also rename participant status to status\n",
    "status_df.rename(columns={'Participant Status ': 'status'}, inplace=True)\n",
    "# Reset the index\n",
    "status_df.reset_index(drop=True, inplace=True)\n",
    "# Add @timestudy_com to the participant_id column\n",
    "status_df['participant_id'] = status_df['participant_id'] + '@timestudy_com'\n",
    "## Show the first few rows\n",
    "print(status_df.head())\n",
    "# Also print the shape of the dataframe\n",
    "print(status_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0f031",
   "metadata": {},
   "source": [
    "Save the completed participants IDs as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3909442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sharpnessnextpouch@timestudy_com', 'dimnesscranialunheard@timestudy_com', 'coynessculminatebarista@timestudy_com', 'spinstersubatomiccoyness@timestudy_com', 'sadlyskilledlustfully@timestudy_com', 'unfittedfactoiddivisive@timestudy_com', 'groinunratedbattery@timestudy_com', 'exploreparadoxmangle@timestudy_com', 'penpalsandbanklifting@timestudy_com', 'showplacefacingsanta@timestudy_com', 'lyricallymalformedrigor@timestudy_com', 'neutergoldfishsworn@timestudy_com', 'debatableuneasyeveryone@timestudy_com', 'peddlingventricleexert@timestudy_com', 'collisionmolarbreeze@timestudy_com', 'faucetsquealingcatapult@timestudy_com', 'bannisterhardwiredladle@timestudy_com', 'resupplyclappingyahoo@timestudy_com', 'punctuatelandingdeferred@timestudy_com', 'tattlingsupperlegroom@timestudy_com', 'vagabondnumerousflatterer@timestudy_com', 'anagramprobingscrooge@timestudy_com', 'equallustinessuntil@timestudy_com', 'crestedserpentspongy@timestudy_com', 'fracturerepurposealgebra@timestudy_com', 'cohesiveprotractfavored@timestudy_com', 'attirecrabbinghumbling@timestudy_com', 'lardcapablemud@timestudy_com', 'badlandwiltmuseum@timestudy_com', 'catsupexploitmocker@timestudy_com', 'reconfirmcremeplethora@timestudy_com', 'pretendedconstrainfraying@timestudy_com', 'feistydaycarelung@timestudy_com', 'gentlykittenthaw@timestudy_com', 'rebuttalskateroyster@timestudy_com', 'atlanticchefhatchet@timestudy_com', 'rangerchildlikequantum@timestudy_com', 'kinsmanlargewand@timestudy_com', 'chewingslouchingfailing@timestudy_com', 'hardyneatnessclobber@timestudy_com', 'doorpostthesisjubilance@timestudy_com', 'distresslitigatemassager@timestudy_com', 'ogleuncladthermos@timestudy_com', 'grudgehandballcampfire@timestudy_com', 'anthillfastinglucrative@timestudy_com', 'evasiongalorebath@timestudy_com', 'spookysubtotalunreached@timestudy_com', 'sculpturecrunchingerasure@timestudy_com', 'defilinganywayimmovable@timestudy_com', 'parakeettrappeddetector@timestudy_com', 'unmixableresultfidgety@timestudy_com', 'subtitlegrievousbazooka@timestudy_com', 'predatordebatingpredator@timestudy_com', 'massagerresidencyenlarging@timestudy_com', 'wrigglecatalyststerility@timestudy_com', 'dissuadecelestialrelic@timestudy_com', 'childhoodmovingmagnify@timestudy_com', 'congestedculpritsaved@timestudy_com', 'congestedtapssneer@timestudy_com', 'moodinessgrandmasynopsis@timestudy_com', 'starlesspayingoutlet@timestudy_com', 'grumblystiffnessuntainted@timestudy_com', 'arrivejanitoruniformly@timestudy_com', 'diagramuncoupleoutput@timestudy_com', 'residentselfgutter@timestudy_com', 'congresscyclistdefender@timestudy_com', 'animateshowerclothes@timestudy_com', 'retrialgraftedsturdy@timestudy_com', 'tipoffstarchpartly@timestudy_com', 'nicknameoverpaycolt@timestudy_com', 'headphoneoutsmartunfailing@timestudy_com', 'craftworkattendeeensnare@timestudy_com', 'tapestryrivetingverify@timestudy_com', 'unbundleoverbitesixtyfold@timestudy_com', 'routinesurenessglitzy@timestudy_com', 'grapethumpingtwenty@timestudy_com', 'superiorpassablecosmic@timestudy_com', 'wikipediaetchingcrystal@timestudy_com', 'rangerabrasivedislike@timestudy_com', 'idealistsustainerexpansive@timestudy_com', 'panoramahandcraftcomma@timestudy_com', 'urchinvariablytrend@timestudy_com', 'washboardceramicsenticing@timestudy_com', 'slapstickporcupineslacks@timestudy_com', 'pandemicerraticobscure@timestudy_com', 'gammahuffrigging@timestudy_com', 'trombonetroweldecree@timestudy_com', 'sublevelcurlyhanky@timestudy_com', 'endlessroamerreconfirm@timestudy_com', 'larkshiningaffected@timestudy_com', 'synapseevaluatechevron@timestudy_com', 'kangaroozodiaccrudeness@timestudy_com', 'unfreezefrayingknoll@timestudy_com', 'certifiedembargobartender@timestudy_com', 'spearmanshushfreebie@timestudy_com', 'unveileddismountearwig@timestudy_com', 'erasuresafeguardravishing@timestudy_com', 'mountainseclusionchaffing@timestudy_com', 'genderradiantlycharging@timestudy_com', 'earflapmaraudingappointee@timestudy_com', 'persevereriseswoop@timestudy_com', 'unelectedscrubbeddeflected@timestudy_com', 'bartenderradiatorapplied@timestudy_com', 'moisturedecodelyricist@timestudy_com', 'scarecrowstackcharred@timestudy_com', 'rippingpeprepose@timestudy_com', 'resalepartlyfrigidity@timestudy_com', 'backfirebankedprudishly@timestudy_com', 'afflictedrevenueepilepsy@timestudy_com', 'thusflattenengraver@timestudy_com', 'freightbrisklypopulace@timestudy_com', 'bondingcoasterdirtiness@timestudy_com', 'mumblingfoundersubsonic@timestudy_com', 'reliablydetaildebate@timestudy_com', 'yearlingfiberspotty@timestudy_com', 'nucleusbackwatercanning@timestudy_com', 'headwearskirmishantidote@timestudy_com', 'landlordastrologycopy@timestudy_com', 'brinkaminounframed@timestudy_com', 'enjoyergoofinessgrudge@timestudy_com', 'whoeverrelightspookily@timestudy_com', 'caucuscattlemockup@timestudy_com', 'moocherchemicalsbanker@timestudy_com', 'espionagechihuahuagraffiti@timestudy_com', 'remoldexcludingaffair@timestudy_com', 'retrievergeckoabroad@timestudy_com', 'quizzicalpremiumfrayed@timestudy_com', 'facelesschimpacclaim@timestudy_com', 'beavertomatoupscale@timestudy_com', 'housewagontrivial@timestudy_com', 'handcufffootloosecabful@timestudy_com', 'mysidvattedlexica@timestudy_com', 'unraveledlitterpowerably@timestudy_com', 'orbsquackysyllabuses@timestudy_com', 'pettytransfixedsolubly@timestudy_com', 'copybrickcreative@timestudy_com']\n"
     ]
    }
   ],
   "source": [
    "completed_participants = status_df['participant_id'].tolist()\n",
    "# Display the completed participants\n",
    "print(completed_participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc79f3",
   "metadata": {},
   "source": [
    "## Import compliance matrix\n",
    "We will import hourly compliance matrix for all the completed participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34420711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Participant_ID Initial_Prompt_Date Prompt_Type  \\\n",
      "0  sharpnessnextpouch@timestudy_com          2020-06-24   EMA_Micro   \n",
      "1  sharpnessnextpouch@timestudy_com          2020-06-24   EMA_Micro   \n",
      "2  sharpnessnextpouch@timestudy_com          2020-06-24   EMA_Micro   \n",
      "3  sharpnessnextpouch@timestudy_com          2020-06-24   EMA_Micro   \n",
      "4  sharpnessnextpouch@timestudy_com          2020-06-24   EMA_Micro   \n",
      "\n",
      "  Study_Mode     Initial_Prompt_Local_Time Answer_Status  \\\n",
      "0       TIME  Wed Jun 24 05:34:02 PDT 2020     Completed   \n",
      "1       TIME  Wed Jun 24 05:43:02 PDT 2020     Completed   \n",
      "2       TIME  Wed Jun 24 05:51:02 PDT 2020     Completed   \n",
      "3       TIME  Wed Jun 24 06:14:03 PDT 2020  NeverStarted   \n",
      "4       TIME  Wed Jun 24 06:33:05 PDT 2020     Completed   \n",
      "\n",
      "       Actual_Prompt_Local_Time  First_Question_Completion_Unixtime  \\\n",
      "0  Wed Jun 24 05:34:02 PDT 2020                       1593002047735   \n",
      "1  Wed Jun 24 05:43:02 PDT 2020                       1593002586653   \n",
      "2  Wed Jun 24 05:51:02 PDT 2020                       1593003068073   \n",
      "3  Wed Jun 24 06:14:03 PDT 2020                                  -1   \n",
      "4  Wed Jun 24 06:33:05 PDT 2020                       1593005596491   \n",
      "\n",
      "  UTC_Offset  Reprompt_Num  ...          start_time_7min   mims_summary_8min  \\\n",
      "0  GMT-07:00             0  ...  2020-06-24 05:27:02.007  25.762841645149287   \n",
      "1  GMT-07:00             0  ...  2020-06-24 05:36:02.007  0.7259144947332565   \n",
      "2  GMT-07:00             0  ...  2020-06-24 05:44:02.007  1.9533181687615095   \n",
      "3  GMT-07:00             0  ...  2020-06-24 06:07:03.003                 0.0   \n",
      "4  GMT-07:00             0  ...  2020-06-24 06:26:05.003                 0.0   \n",
      "\n",
      "   num_readings_8min          start_time_8min   mims_summary_9min  \\\n",
      "0              480.0  2020-06-24 05:26:02.007  25.762841645149287   \n",
      "1              480.0  2020-06-24 05:35:02.007  13.514256394102517   \n",
      "2              480.0  2020-06-24 05:43:02.007  1.9533181687615095   \n",
      "3              480.0  2020-06-24 06:06:03.003                 0.0   \n",
      "4              480.0  2020-06-24 06:25:05.003                 0.0   \n",
      "\n",
      "  num_readings_9min          start_time_9min  mims_summary_10min  \\\n",
      "0             540.0  2020-06-24 05:25:02.007  25.762841645149287   \n",
      "1             540.0  2020-06-24 05:34:02.007  15.953504409952053   \n",
      "2             540.0  2020-06-24 05:42:02.007  1.9533181687615095   \n",
      "3             540.0  2020-06-24 06:05:03.003                 0.0   \n",
      "4             540.0  2020-06-24 06:24:05.003                 0.0   \n",
      "\n",
      "  num_readings_10min         start_time_10min  \n",
      "0              600.0  2020-06-24 05:24:02.007  \n",
      "1              600.0  2020-06-24 05:33:02.007  \n",
      "2              600.0  2020-06-24 05:41:02.007  \n",
      "3              600.0  2020-06-24 06:04:03.003  \n",
      "4              600.0  2020-06-24 06:23:05.003  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "(1495495, 62)\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/adityaponnada/Downloads/time_study_data/compliance_matrix/'\n",
    "# Import all the csv files within this folder. But only for the completed participants. Then concatenate them into a single dataframe.\n",
    "# Note: The folder is structured as follows:\n",
    "# folder_path/participant_id/uema_feature_mx_*.csv. Here * is a wildcard that matches any characters.\n",
    "# The code should first use the completed participant list, then loop through the folder path and find p[articipant_id folder. \n",
    "# Then once the matching folder found, just concatinate all the csv files that match the pattern uema_feature_mx_*.csv\n",
    "all_files = []\n",
    "for participant in completed_participants:\n",
    "    participant_folder = f\"{folder_path}{participant}/\"\n",
    "    # Find all the csv files that match the pattern uema_feature_mx_*.csv\n",
    "    files = glob.glob(participant_folder + 'uema_feature_mx_*.csv')\n",
    "    for file in files:\n",
    "        all_files.append(pd.read_csv(file))\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "compliance_matrix = pd.concat(all_files, ignore_index=True)\n",
    "# Show the first few rows of the compliance matrix\n",
    "print(compliance_matrix.head())\n",
    "# Also print the shape of the compliance matrix\n",
    "print(compliance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3cab574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in compliance_matrix: 1495495\n",
      "Number of columns in compliance_matrix: 62\n",
      "Number of unique participants in compliance_matrix: 137\n"
     ]
    }
   ],
   "source": [
    "## Get the number of rows in compliance_matrix\n",
    "num_rows = compliance_matrix.shape[0]\n",
    "print(f\"Number of rows in compliance_matrix: {num_rows}\")\n",
    "# Get the number of columns in compliance_matrix\n",
    "num_cols = compliance_matrix.shape[1]\n",
    "print(f\"Number of columns in compliance_matrix: {num_cols}\")\n",
    "# Get the number of unique participants in compliance_matrix\n",
    "num_participants = compliance_matrix['Participant_ID'].nunique()\n",
    "print(f\"Number of unique participants in compliance_matrix: {num_participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218f7f2",
   "metadata": {},
   "source": [
    "Save the file for later access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eec35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compliance matrix saved to /Users/adityaponnada/Downloads/time_study_data/compliance_matrix_20250701_115558.csv\n"
     ]
    }
   ],
   "source": [
    "## Save compliance_matrix to a csv file. The filename should have _date_time appended to it.\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "compliance_matrix.to_csv(f'/Users/adityaponnada/Downloads/time_study_data/compliance_matrix_{current_time}.csv', index=False)\n",
    "print(f\"Compliance matrix saved to /Users/adityaponnada/Downloads/time_study_data/compliance_matrix_{current_time}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
