{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910898c2",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "This notebook imports participant data from TIME study, keeps only those who completed the study, comutes all the features, then saves two files:\n",
    "1. Feature set for all the users\n",
    "2. A sample of users to try different ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93d803",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "Import essential libraries here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3fd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797cc3d",
   "metadata": {},
   "source": [
    "## Import participant status\n",
    "We will import participant status data. So that we can filter out those who completed the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b2aa2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Record ID            Visualizer ID Participant Status  Consent Date  \\\n",
      "0       9001       sharpnessnextpouch           Completed    3/17/2020   \n",
      "1       9002     uniformlyharmfulbush          Unenrolled    3/18/2020   \n",
      "2       9003     hacksawscoldingdares            Withdrew    3/27/2020   \n",
      "3       9004    dimnesscranialunheard           Completed    3/28/2020   \n",
      "4       9005  coynessculminatebarista           Completed     4/8/2020   \n",
      "\n",
      "  Date participant completed Date participant withdrew  \\\n",
      "0                  3/17/2021                       NaN   \n",
      "1                        NaN                       NaN   \n",
      "2                        NaN                 12/4/2020   \n",
      "3                  3/28/2021                       NaN   \n",
      "4                   4/8/2021                       NaN   \n",
      "\n",
      "  Date participant unenrolled Date Devices Mailed ID of device loaned  \\\n",
      "0                         NaN           3/25/2020        C2F9214C2188   \n",
      "1                  10/20/2020           3/25/2020        C2F9202C1141   \n",
      "2                         NaN            4/7/2020        C2F9153C0327   \n",
      "3                         NaN            4/7/2020        C2F9151C0324   \n",
      "4                         NaN           4/14/2020        C2F9262C1610   \n",
      "\n",
      "  Watch training date  Exit Interview Date  \n",
      "0            3/28/2020           3/19/2021  \n",
      "1            3/28/2020                 NaN  \n",
      "2            4/10/2020                 NaN  \n",
      "3            4/13/2020                 NaN  \n",
      "4            4/20/2020                 NaN  \n",
      "Index(['Record ID', 'Visualizer ID', 'Participant Status ', 'Consent Date',\n",
      "       'Date participant completed', 'Date participant withdrew',\n",
      "       'Date participant unenrolled', 'Date Devices Mailed',\n",
      "       'ID of device loaned', 'Watch training date ', 'Exit Interview Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Import the status file\n",
    "status_file = '/Users/adityaponnada/Downloads/time_study_data/participant_status_tracking_v2.csv'\n",
    "status_df = pd.read_csv(status_file)\n",
    "\n",
    "## Show the first few rows\n",
    "print(status_df.head())\n",
    "# Also print the columns names\n",
    "print(status_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02ca55",
   "metadata": {},
   "source": [
    "Now only keep the completed participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33ced38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           participant_id     status\n",
      "0        sharpnessnextpouch@timestudy_com  Completed\n",
      "1     dimnesscranialunheard@timestudy_com  Completed\n",
      "2   coynessculminatebarista@timestudy_com  Completed\n",
      "3  spinstersubatomiccoyness@timestudy_com  Completed\n",
      "4     sadlyskilledlustfully@timestudy_com  Completed\n",
      "(136, 2)\n"
     ]
    }
   ],
   "source": [
    "## Filter completed participants. We will only keep the visualizerID and status columns\n",
    "status_df = status_df[status_df['Participant Status '] == 'Completed'][['Visualizer ID', 'Participant Status ']]\n",
    "# Rename the visualizerID column to participant_id.\n",
    "status_df.rename(columns={'Visualizer ID': 'participant_id'}, inplace=True)\n",
    "# Also rename participant status to status\n",
    "status_df.rename(columns={'Participant Status ': 'status'}, inplace=True)\n",
    "# Reset the index\n",
    "status_df.reset_index(drop=True, inplace=True)\n",
    "# Add @timestudy_com to the participant_id column\n",
    "status_df['participant_id'] = status_df['participant_id'] + '@timestudy_com'\n",
    "## Show the first few rows\n",
    "print(status_df.head())\n",
    "# Also print the shape of the dataframe\n",
    "print(status_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0f031",
   "metadata": {},
   "source": [
    "Save the completed participants IDs as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3909442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afflictedrevenueepilepsy@timestudy_com', 'anagramprobingscrooge@timestudy_com', 'animateshowerclothes@timestudy_com', 'anthillfastinglucrative@timestudy_com', 'arrivejanitoruniformly@timestudy_com', 'atlanticchefhatchet@timestudy_com', 'attirecrabbinghumbling@timestudy_com', 'backfirebankedprudishly@timestudy_com', 'badlandwiltmuseum@timestudy_com', 'bannisterhardwiredladle@timestudy_com', 'bartenderradiatorapplied@timestudy_com', 'beavertomatoupscale@timestudy_com', 'bondingcoasterdirtiness@timestudy_com', 'brinkaminounframed@timestudy_com', 'catsupexploitmocker@timestudy_com', 'caucuscattlemockup@timestudy_com', 'certifiedembargobartender@timestudy_com', 'chewingslouchingfailing@timestudy_com', 'childhoodmovingmagnify@timestudy_com', 'cohesiveprotractfavored@timestudy_com', 'collisionmolarbreeze@timestudy_com', 'congestedculpritsaved@timestudy_com', 'congestedtapssneer@timestudy_com', 'congresscyclistdefender@timestudy_com', 'copybrickcreative@timestudy_com', 'coynessculminatebarista@timestudy_com', 'craftworkattendeeensnare@timestudy_com', 'crestedserpentspongy@timestudy_com', 'debatableuneasyeveryone@timestudy_com', 'defilinganywayimmovable@timestudy_com', 'diagramuncoupleoutput@timestudy_com', 'dimnesscranialunheard@timestudy_com', 'dissuadecelestialrelic@timestudy_com', 'distresslitigatemassager@timestudy_com', 'doorpostthesisjubilance@timestudy_com', 'earflapmaraudingappointee@timestudy_com', 'endlessroamerreconfirm@timestudy_com', 'enjoyergoofinessgrudge@timestudy_com', 'equallustinessuntil@timestudy_com', 'erasuresafeguardravishing@timestudy_com', 'espionagechihuahuagraffiti@timestudy_com', 'evasiongalorebath@timestudy_com', 'exploreparadoxmangle@timestudy_com', 'facelesschimpacclaim@timestudy_com', 'faucetsquealingcatapult@timestudy_com', 'feistydaycarelung@timestudy_com', 'fracturerepurposealgebra@timestudy_com', 'freightbrisklypopulace@timestudy_com', 'gammahuffrigging@timestudy_com', 'genderradiantlycharging@timestudy_com', 'gentlykittenthaw@timestudy_com', 'grapethumpingtwenty@timestudy_com', 'groinunratedbattery@timestudy_com', 'grudgehandballcampfire@timestudy_com', 'grumblystiffnessuntainted@timestudy_com', 'handcufffootloosecabful@timestudy_com', 'hardyneatnessclobber@timestudy_com', 'headphoneoutsmartunfailing@timestudy_com', 'headwearskirmishantidote@timestudy_com', 'housewagontrivial@timestudy_com', 'idealistsustainerexpansive@timestudy_com', 'kangaroozodiaccrudeness@timestudy_com', 'kinsmanlargewand@timestudy_com', 'landlordastrologycopy@timestudy_com', 'lardcapablemud@timestudy_com', 'larkshiningaffected@timestudy_com', 'lyricallymalformedrigor@timestudy_com', 'massagerresidencyenlarging@timestudy_com', 'moisturedecodelyricist@timestudy_com', 'moocherchemicalsbanker@timestudy_com', 'moodinessgrandmasynopsis@timestudy_com', 'mountainseclusionchaffing@timestudy_com', 'mumblingfoundersubsonic@timestudy_com', 'mysidvattedlexica@timestudy_com', 'neutergoldfishsworn@timestudy_com', 'nicknameoverpaycolt@timestudy_com', 'nucleusbackwatercanning@timestudy_com', 'ogleuncladthermos@timestudy_com', 'orbsquackysyllabuses@timestudy_com', 'pandemicerraticobscure@timestudy_com', 'panoramahandcraftcomma@timestudy_com', 'parakeettrappeddetector@timestudy_com', 'peddlingventricleexert@timestudy_com', 'penpalsandbanklifting@timestudy_com', 'persevereriseswoop@timestudy_com', 'pettytransfixedsolubly@timestudy_com', 'predatordebatingpredator@timestudy_com', 'pretendedconstrainfraying@timestudy_com', 'punctuatelandingdeferred@timestudy_com', 'quizzicalpremiumfrayed@timestudy_com', 'rangerabrasivedislike@timestudy_com', 'rangerchildlikequantum@timestudy_com', 'rebuttalskateroyster@timestudy_com', 'reconfirmcremeplethora@timestudy_com', 'reliablydetaildebate@timestudy_com', 'remoldexcludingaffair@timestudy_com', 'resalepartlyfrigidity@timestudy_com', 'residentselfgutter@timestudy_com', 'resupplyclappingyahoo@timestudy_com', 'retrialgraftedsturdy@timestudy_com', 'retrievergeckoabroad@timestudy_com', 'rippingpeprepose@timestudy_com', 'routinesurenessglitzy@timestudy_com', 'sadlyskilledlustfully@timestudy_com', 'scarecrowstackcharred@timestudy_com', 'sculpturecrunchingerasure@timestudy_com', 'sharpnessnextpouch@timestudy_com', 'showplacefacingsanta@timestudy_com', 'slapstickporcupineslacks@timestudy_com', 'spearmanshushfreebie@timestudy_com', 'spinstersubatomiccoyness@timestudy_com', 'spookysubtotalunreached@timestudy_com', 'starlesspayingoutlet@timestudy_com', 'sublevelcurlyhanky@timestudy_com', 'subtitlegrievousbazooka@timestudy_com', 'superiorpassablecosmic@timestudy_com', 'synapseevaluatechevron@timestudy_com', 'tapestryrivetingverify@timestudy_com', 'tattlingsupperlegroom@timestudy_com', 'thusflattenengraver@timestudy_com', 'tipoffstarchpartly@timestudy_com', 'trombonetroweldecree@timestudy_com', 'unbundleoverbitesixtyfold@timestudy_com', 'unelectedscrubbeddeflected@timestudy_com', 'unfittedfactoiddivisive@timestudy_com', 'unfreezefrayingknoll@timestudy_com', 'unmixableresultfidgety@timestudy_com', 'unraveledlitterpowerably@timestudy_com', 'unveileddismountearwig@timestudy_com', 'urchinvariablytrend@timestudy_com', 'vagabondnumerousflatterer@timestudy_com', 'washboardceramicsenticing@timestudy_com', 'whoeverrelightspookily@timestudy_com', 'wikipediaetchingcrystal@timestudy_com', 'wrigglecatalyststerility@timestudy_com', 'yearlingfiberspotty@timestudy_com']\n",
      "Total completed participants: 136\n"
     ]
    }
   ],
   "source": [
    "completed_participants = status_df['participant_id'].sort_values().tolist()\n",
    "# Display the completed participants\n",
    "print(completed_participants)\n",
    "print(f\"Total completed participants: {len(completed_participants)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a8cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training list size: 100\n",
      "Holdout list size: 36\n",
      "Training sample (first 10): ['headphoneoutsmartunfailing@timestudy_com', 'retrialgraftedsturdy@timestudy_com', 'landlordastrologycopy@timestudy_com', 'bartenderradiatorapplied@timestudy_com', 'backfirebankedprudishly@timestudy_com', 'bannisterhardwiredladle@timestudy_com', 'unfreezefrayingknoll@timestudy_com', 'endlessroamerreconfirm@timestudy_com', 'unmixableresultfidgety@timestudy_com', 'equallustinessuntil@timestudy_com']\n",
      "Holdout sample (first 10): ['animateshowerclothes@timestudy_com', 'atlanticchefhatchet@timestudy_com', 'beavertomatoupscale@timestudy_com', 'bondingcoasterdirtiness@timestudy_com', 'childhoodmovingmagnify@timestudy_com', 'cohesiveprotractfavored@timestudy_com', 'collisionmolarbreeze@timestudy_com', 'congestedculpritsaved@timestudy_com', 'congestedtapssneer@timestudy_com', 'crestedserpentspongy@timestudy_com']\n"
     ]
    }
   ],
   "source": [
    "# Split completed_participants into training_list and holdout_list with non-deterministic sampling\n",
    "import random\n",
    "\n",
    "n_train = min(100, len(completed_participants))\n",
    "if len(completed_participants) == 0:\n",
    "    training_list = []\n",
    "    holdout_list = []\n",
    "else:\n",
    "    # random.sample is non-deterministic by default (system RNG); each run will differ\n",
    "    training_list = random.sample(completed_participants, k=n_train)\n",
    "    holdout_set = set(training_list)\n",
    "    # preserve original order for holdout_list\n",
    "    holdout_list = [p for p in completed_participants if p not in holdout_set]\n",
    "\n",
    "print(f'Training list size: {len(training_list)}')\n",
    "print(f'Holdout list size: {len(holdout_list)}')\n",
    "print('Training sample (first 10):', training_list[:10])\n",
    "print('Holdout sample (first 10):', holdout_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc79f3",
   "metadata": {},
   "source": [
    "## Import compliance matrix\n",
    "We will import hourly compliance matrix for all the completed participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e4d720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading participant: headphoneoutsmartunfailing@timestudy_com | files: 276\n",
      "Reading participant: retrialgraftedsturdy@timestudy_com | files: 84\n",
      "Reading participant: landlordastrologycopy@timestudy_com | files: 225\n",
      "Reading participant: retrialgraftedsturdy@timestudy_com | files: 84\n",
      "Reading participant: landlordastrologycopy@timestudy_com | files: 225\n",
      "Reading participant: bartenderradiatorapplied@timestudy_com | files: 94\n",
      "Reading participant: backfirebankedprudishly@timestudy_com | files: 251\n",
      "Reading participant: bartenderradiatorapplied@timestudy_com | files: 94\n",
      "Reading participant: backfirebankedprudishly@timestudy_com | files: 251\n",
      "Reading participant: bannisterhardwiredladle@timestudy_com | files: 268\n",
      "Reading participant: bannisterhardwiredladle@timestudy_com | files: 268\n",
      "Reading participant: unfreezefrayingknoll@timestudy_com | files: 243\n",
      "Reading participant: unfreezefrayingknoll@timestudy_com | files: 243\n",
      "Reading participant: endlessroamerreconfirm@timestudy_com | files: 209\n",
      "Reading participant: endlessroamerreconfirm@timestudy_com | files: 209\n",
      "Reading participant: unmixableresultfidgety@timestudy_com | files: 247\n",
      "Reading participant: unmixableresultfidgety@timestudy_com | files: 247\n",
      "Reading participant: equallustinessuntil@timestudy_com | files: 221\n",
      "Reading participant: equallustinessuntil@timestudy_com | files: 221\n",
      "Reading participant: vagabondnumerousflatterer@timestudy_com | files: 223\n",
      "Reading participant: vagabondnumerousflatterer@timestudy_com | files: 223\n",
      "Reading participant: massagerresidencyenlarging@timestudy_com | files: 211\n",
      "Reading participant: massagerresidencyenlarging@timestudy_com | files: 211\n",
      "Reading participant: remoldexcludingaffair@timestudy_com | files: 170\n",
      "Reading participant: remoldexcludingaffair@timestudy_com | files: 170\n",
      "Reading participant: sculpturecrunchingerasure@timestudy_com | files: 249\n",
      "Reading participant: sculpturecrunchingerasure@timestudy_com | files: 249\n",
      "Reading participant: ogleuncladthermos@timestudy_com | files: 250\n",
      "Reading participant: ogleuncladthermos@timestudy_com | files: 250\n",
      "Reading participant: washboardceramicsenticing@timestudy_com | files: 273\n",
      "Reading participant: washboardceramicsenticing@timestudy_com | files: 273\n",
      "Reading participant: unfittedfactoiddivisive@timestudy_com | files: 145\n",
      "Reading participant: unfittedfactoiddivisive@timestudy_com | files: 145\n",
      "Reading participant: doorpostthesisjubilance@timestudy_com | files: 249\n",
      "Reading participant: doorpostthesisjubilance@timestudy_com | files: 249\n",
      "Reading participant: copybrickcreative@timestudy_com | files: 234\n",
      "Reading participant: copybrickcreative@timestudy_com | files: 234\n",
      "Reading participant: tattlingsupperlegroom@timestudy_com | files: 245\n",
      "Reading participant: tattlingsupperlegroom@timestudy_com | files: 245\n",
      "Reading participant: spearmanshushfreebie@timestudy_com | files: 249\n",
      "Reading participant: spearmanshushfreebie@timestudy_com | files: 249\n",
      "Reading participant: craftworkattendeeensnare@timestudy_com | files: 270\n",
      "Reading participant: craftworkattendeeensnare@timestudy_com | files: 270\n",
      "Reading participant: diagramuncoupleoutput@timestudy_com | files: 227\n",
      "Reading participant: diagramuncoupleoutput@timestudy_com | files: 227\n",
      "Reading participant: showplacefacingsanta@timestudy_com | files: 254\n",
      "Reading participant: showplacefacingsanta@timestudy_com | files: 254\n",
      "Reading participant: rangerchildlikequantum@timestudy_com | files: 245\n",
      "Reading participant: rangerchildlikequantum@timestudy_com | files: 245\n",
      "Reading participant: caucuscattlemockup@timestudy_com | files: 248\n",
      "Reading participant: caucuscattlemockup@timestudy_com | files: 248\n",
      "Reading participant: spinstersubatomiccoyness@timestudy_com | files: 224\n",
      "Reading participant: spinstersubatomiccoyness@timestudy_com | files: 224\n",
      "Reading participant: coynessculminatebarista@timestudy_com | files: 234\n",
      "Reading participant: coynessculminatebarista@timestudy_com | files: 234\n",
      "Reading participant: wikipediaetchingcrystal@timestudy_com | files: 250\n",
      "Reading participant: wikipediaetchingcrystal@timestudy_com | files: 250\n",
      "Reading participant: mysidvattedlexica@timestudy_com | files: 216\n",
      "Reading participant: mysidvattedlexica@timestudy_com | files: 216\n",
      "Reading participant: afflictedrevenueepilepsy@timestudy_com | files: 254\n",
      "Reading participant: afflictedrevenueepilepsy@timestudy_com | files: 254\n",
      "Reading participant: freightbrisklypopulace@timestudy_com | files: 235\n",
      "Reading participant: freightbrisklypopulace@timestudy_com | files: 235\n",
      "Reading participant: synapseevaluatechevron@timestudy_com | files: 195\n",
      "Reading participant: synapseevaluatechevron@timestudy_com | files: 195\n",
      "Reading participant: gammahuffrigging@timestudy_com | files: 252\n",
      "Reading participant: gammahuffrigging@timestudy_com | files: 252\n",
      "Reading participant: arrivejanitoruniformly@timestudy_com | files: 273\n",
      "Reading participant: arrivejanitoruniformly@timestudy_com | files: 273\n",
      "Reading participant: pandemicerraticobscure@timestudy_com | files: 248\n",
      "Reading participant: pandemicerraticobscure@timestudy_com | files: 248\n",
      "Reading participant: unelectedscrubbeddeflected@timestudy_com | files: 157\n",
      "Reading participant: unelectedscrubbeddeflected@timestudy_com | files: 157\n",
      "Reading participant: sadlyskilledlustfully@timestudy_com | files: 250\n",
      "Reading participant: sadlyskilledlustfully@timestudy_com | files: 250\n",
      "Reading participant: retrievergeckoabroad@timestudy_com | files: 4\n",
      "Reading participant: residentselfgutter@timestudy_com | files: 262\n",
      "Reading participant: retrievergeckoabroad@timestudy_com | files: 4\n",
      "Reading participant: residentselfgutter@timestudy_com | files: 262\n",
      "Reading participant: espionagechihuahuagraffiti@timestudy_com | files: 243\n",
      "Reading participant: espionagechihuahuagraffiti@timestudy_com | files: 243\n",
      "Reading participant: pretendedconstrainfraying@timestudy_com | files: 270\n",
      "Reading participant: pretendedconstrainfraying@timestudy_com | files: 270\n",
      "Reading participant: orbsquackysyllabuses@timestudy_com | files: 234\n",
      "Reading participant: orbsquackysyllabuses@timestudy_com | files: 234\n",
      "Reading participant: grumblystiffnessuntainted@timestudy_com | files: 262\n",
      "Reading participant: grumblystiffnessuntainted@timestudy_com | files: 262\n",
      "Reading participant: erasuresafeguardravishing@timestudy_com | files: 141\n",
      "Reading participant: erasuresafeguardravishing@timestudy_com | files: 141\n",
      "Reading participant: chewingslouchingfailing@timestudy_com | files: 249\n",
      "Reading participant: chewingslouchingfailing@timestudy_com | files: 249\n",
      "Reading participant: resupplyclappingyahoo@timestudy_com | files: 177\n",
      "Reading participant: resupplyclappingyahoo@timestudy_com | files: 177\n",
      "Reading participant: attirecrabbinghumbling@timestudy_com | files: 255\n",
      "Reading participant: attirecrabbinghumbling@timestudy_com | files: 255\n",
      "Reading participant: yearlingfiberspotty@timestudy_com | files: 244\n",
      "Reading participant: yearlingfiberspotty@timestudy_com | files: 244\n",
      "Reading participant: headwearskirmishantidote@timestudy_com | files: 275\n",
      "Reading participant: headwearskirmishantidote@timestudy_com | files: 275\n",
      "Reading participant: dissuadecelestialrelic@timestudy_com | files: 237\n",
      "Reading participant: dissuadecelestialrelic@timestudy_com | files: 237\n",
      "Reading participant: kinsmanlargewand@timestudy_com | files: 277\n",
      "Reading participant: kinsmanlargewand@timestudy_com | files: 277\n",
      "Reading participant: nicknameoverpaycolt@timestudy_com | files: 140\n",
      "Reading participant: nicknameoverpaycolt@timestudy_com | files: 140\n",
      "Reading participant: grudgehandballcampfire@timestudy_com | files: 263\n",
      "Reading participant: grudgehandballcampfire@timestudy_com | files: 263\n",
      "Reading participant: kangaroozodiaccrudeness@timestudy_com | files: 200\n",
      "Reading participant: kangaroozodiaccrudeness@timestudy_com | files: 200\n",
      "Reading participant: unveileddismountearwig@timestudy_com | files: 249\n",
      "Reading participant: unveileddismountearwig@timestudy_com | files: 249\n",
      "Reading participant: pettytransfixedsolubly@timestudy_com | files: 103\n",
      "Reading participant: pettytransfixedsolubly@timestudy_com | files: 103\n",
      "Reading participant: facelesschimpacclaim@timestudy_com | files: 27\n",
      "Reading participant: nucleusbackwatercanning@timestudy_com | files: 262\n",
      "Reading participant: facelesschimpacclaim@timestudy_com | files: 27\n",
      "Reading participant: nucleusbackwatercanning@timestudy_com | files: 262\n",
      "Reading participant: housewagontrivial@timestudy_com | files: 85\n",
      "Reading participant: trombonetroweldecree@timestudy_com | files: 243\n",
      "Reading participant: housewagontrivial@timestudy_com | files: 85\n",
      "Reading participant: trombonetroweldecree@timestudy_com | files: 243\n",
      "Reading participant: hardyneatnessclobber@timestudy_com | files: 248\n",
      "Reading participant: hardyneatnessclobber@timestudy_com | files: 248\n",
      "Reading participant: anagramprobingscrooge@timestudy_com | files: 248\n",
      "Reading participant: anagramprobingscrooge@timestudy_com | files: 248\n",
      "Reading participant: earflapmaraudingappointee@timestudy_com | files: 138\n",
      "Reading participant: earflapmaraudingappointee@timestudy_com | files: 138\n",
      "Reading participant: lyricallymalformedrigor@timestudy_com | files: 271\n",
      "Reading participant: lyricallymalformedrigor@timestudy_com | files: 271\n",
      "Reading participant: superiorpassablecosmic@timestudy_com | files: 245\n",
      "Reading participant: superiorpassablecosmic@timestudy_com | files: 245\n",
      "Reading participant: moocherchemicalsbanker@timestudy_com | files: 261\n",
      "Reading participant: moocherchemicalsbanker@timestudy_com | files: 261\n",
      "Reading participant: routinesurenessglitzy@timestudy_com | files: 230\n",
      "Reading participant: routinesurenessglitzy@timestudy_com | files: 230\n",
      "Reading participant: reconfirmcremeplethora@timestudy_com | files: 265\n",
      "Reading participant: reconfirmcremeplethora@timestudy_com | files: 265\n",
      "Reading participant: urchinvariablytrend@timestudy_com | files: 275\n",
      "Reading participant: urchinvariablytrend@timestudy_com | files: 275\n",
      "Reading participant: parakeettrappeddetector@timestudy_com | files: 229\n",
      "Reading participant: parakeettrappeddetector@timestudy_com | files: 229\n",
      "Reading participant: badlandwiltmuseum@timestudy_com | files: 220\n",
      "Reading participant: badlandwiltmuseum@timestudy_com | files: 220\n",
      "Reading participant: reliablydetaildebate@timestudy_com | files: 245\n",
      "Reading participant: reliablydetaildebate@timestudy_com | files: 245\n",
      "Reading participant: moodinessgrandmasynopsis@timestudy_com | files: 255\n",
      "Reading participant: moodinessgrandmasynopsis@timestudy_com | files: 255\n",
      "Reading participant: thusflattenengraver@timestudy_com | files: 17\n",
      "Reading participant: punctuatelandingdeferred@timestudy_com | files: 252\n",
      "Reading participant: thusflattenengraver@timestudy_com | files: 17\n",
      "Reading participant: punctuatelandingdeferred@timestudy_com | files: 252\n",
      "Reading participant: rebuttalskateroyster@timestudy_com | files: 237\n",
      "Reading participant: rebuttalskateroyster@timestudy_com | files: 237\n",
      "Reading participant: anthillfastinglucrative@timestudy_com | files: 245\n",
      "Reading participant: anthillfastinglucrative@timestudy_com | files: 245\n",
      "Reading participant: starlesspayingoutlet@timestudy_com | files: 281\n",
      "Reading participant: starlesspayingoutlet@timestudy_com | files: 281\n",
      "Reading participant: tipoffstarchpartly@timestudy_com | files: 246\n",
      "Reading participant: tipoffstarchpartly@timestudy_com | files: 246\n",
      "Reading participant: certifiedembargobartender@timestudy_com | files: 246\n",
      "Reading participant: certifiedembargobartender@timestudy_com | files: 246\n",
      "Reading participant: exploreparadoxmangle@timestudy_com | files: 237\n",
      "Reading participant: exploreparadoxmangle@timestudy_com | files: 237\n",
      "Reading participant: slapstickporcupineslacks@timestudy_com | files: 219\n",
      "Reading participant: slapstickporcupineslacks@timestudy_com | files: 219\n",
      "Reading participant: distresslitigatemassager@timestudy_com | files: 253\n",
      "Reading participant: distresslitigatemassager@timestudy_com | files: 253\n",
      "Reading participant: predatordebatingpredator@timestudy_com | files: 253\n",
      "Reading participant: predatordebatingpredator@timestudy_com | files: 253\n",
      "Reading participant: catsupexploitmocker@timestudy_com | files: 255\n",
      "Reading participant: catsupexploitmocker@timestudy_com | files: 255\n",
      "Reading participant: wrigglecatalyststerility@timestudy_com | files: 243\n",
      "Reading participant: wrigglecatalyststerility@timestudy_com | files: 243\n",
      "Reading participant: defilinganywayimmovable@timestudy_com | files: 187\n",
      "Reading participant: defilinganywayimmovable@timestudy_com | files: 187\n",
      "Reading participant: scarecrowstackcharred@timestudy_com | files: 234\n",
      "Reading participant: scarecrowstackcharred@timestudy_com | files: 234\n",
      "Reading participant: congresscyclistdefender@timestudy_com | files: 228\n",
      "Reading participant: congresscyclistdefender@timestudy_com | files: 228\n",
      "Reading participant: unbundleoverbitesixtyfold@timestudy_com | files: 245\n",
      "Reading participant: unbundleoverbitesixtyfold@timestudy_com | files: 245\n",
      "Reading participant: debatableuneasyeveryone@timestudy_com | files: 235\n",
      "Reading participant: debatableuneasyeveryone@timestudy_com | files: 235\n",
      "Reading participant: penpalsandbanklifting@timestudy_com | files: 246\n",
      "Reading participant: penpalsandbanklifting@timestudy_com | files: 246\n",
      "Reading participant: brinkaminounframed@timestudy_com | files: 221\n",
      "Reading participant: brinkaminounframed@timestudy_com | files: 221\n",
      "Reading participant: mumblingfoundersubsonic@timestudy_com | files: 214\n",
      "Reading participant: mumblingfoundersubsonic@timestudy_com | files: 214\n",
      "Reading participant: neutergoldfishsworn@timestudy_com | files: 185\n",
      "Reading participant: neutergoldfishsworn@timestudy_com | files: 185\n",
      "Reading participant: evasiongalorebath@timestudy_com | files: 222\n",
      "Reading participant: evasiongalorebath@timestudy_com | files: 222\n",
      "Reading participant: grapethumpingtwenty@timestudy_com | files: 231\n",
      "Reading participant: grapethumpingtwenty@timestudy_com | files: 231\n",
      "Reading participant: handcufffootloosecabful@timestudy_com | files: 223\n",
      "Reading participant: handcufffootloosecabful@timestudy_com | files: 223\n",
      "Reading participant: groinunratedbattery@timestudy_com | files: 250\n",
      "Reading participant: groinunratedbattery@timestudy_com | files: 250\n",
      "Final compliance_matrix rows,cols: (1088971, 63)\n",
      "Final compliance_matrix rows,cols: (1088971, 63)\n",
      "Approx memory (bytes): 3455631096\n",
      "Approx memory (bytes): 3455631096\n"
     ]
    }
   ],
   "source": [
    "# Load uema_feature_mx_*.csv only for participants in completed_participants\n",
    "import os, gc, glob\n",
    "from pandas.errors import EmptyDataError\n",
    "\n",
    "root_folder = '/Users/adityaponnada/Downloads/time_study_data/compliance_matrix/'\n",
    "chunk_size = 10000\n",
    "\n",
    "# normalize and dedupe completed_participants (preserve order)\n",
    "normalized = []\n",
    "seen = set()\n",
    "for p in training_list:\n",
    "    key = str(p).strip()\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        normalized.append(key)\n",
    "training_list = normalized\n",
    "\n",
    "# Only keep IDs that match the expected folder pattern (example: *@timestudy_com)\n",
    "training_list = [p for p in training_list if p.endswith('@timestudy_com')]\n",
    "\n",
    "# accumulator for per-participant DataFrames (keeps memory lower than appending many small dfs)\n",
    "participant_dfs = []\n",
    "\n",
    "for pid in training_list:\n",
    "    participant_folder = os.path.join(root_folder, pid)\n",
    "    if not os.path.isdir(participant_folder):\n",
    "        # skip missing participant folders\n",
    "        continue\n",
    "    # find files matching pattern\n",
    "    files = sorted(glob.glob(os.path.join(participant_folder, 'uema_feature_mx_*.csv')))\n",
    "    if not files:\n",
    "        continue\n",
    "    # read files for this participant in chunks and accumulate into a list\n",
    "    print(f'Reading participant: {pid} | files: {len(files)}')\n",
    "    per_parts = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            reader = pd.read_csv(fp, chunksize=chunk_size, low_memory=True)\n",
    "            for chunk in reader:\n",
    "                per_parts.append(chunk)\n",
    "        except EmptyDataError:\n",
    "            # skip empty files\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f'Failed reading {fp}: {e}')\n",
    "    if per_parts:\n",
    "        # concat per-participant chunks to a single dataframe to reduce number of objects\n",
    "        try:\n",
    "            df_pid = pd.concat(per_parts, ignore_index=True)\n",
    "        except ValueError:\n",
    "            # in case concat fails, skip this participant\n",
    "            continue\n",
    "        # optionally tag the source participant id so downstream code knows origin\n",
    "        df_pid['participant_id_source'] = pid\n",
    "        participant_dfs.append(df_pid)\n",
    "        # cleanup\n",
    "        del per_parts\n",
    "        gc.collect()\n",
    "\n",
    "# Final concatenation across participants\n",
    "if participant_dfs:\n",
    "    compliance_matrix = pd.concat(participant_dfs, ignore_index=True)\n",
    "else:\n",
    "    compliance_matrix = pd.DataFrame()\n",
    "\n",
    "# report\n",
    "print('Final compliance_matrix rows,cols:', compliance_matrix.shape)\n",
    "if not compliance_matrix.empty:\n",
    "    print('Approx memory (bytes):', compliance_matrix.memory_usage(deep=True).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3cab574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in compliance_matrix: 1088971\n",
      "Number of columns in compliance_matrix: 63\n",
      "Number of unique participants in compliance_matrix: 101\n"
     ]
    }
   ],
   "source": [
    "## Get the number of rows in compliance_matrix\n",
    "num_rows = compliance_matrix.shape[0]\n",
    "print(f\"Number of rows in compliance_matrix: {num_rows}\")\n",
    "# Get the number of columns in compliance_matrix\n",
    "num_cols = compliance_matrix.shape[1]\n",
    "print(f\"Number of columns in compliance_matrix: {num_cols}\")\n",
    "# Get the number of unique participants in compliance_matrix\n",
    "num_participants = compliance_matrix['Participant_ID'].nunique()\n",
    "print(f\"Number of unique participants in compliance_matrix: {num_participants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ce2bdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(training_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4588451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove rows with participant_id is \"unknown_user\"\n",
    "compliance_matrix = compliance_matrix[compliance_matrix['Participant_ID'] != 'unknown_user']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218f7f2",
   "metadata": {},
   "source": [
    "Save the file for later access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eec35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compliance matrix saved to /Users/adityaponnada/Downloads/time_study_data/compliance_matrix_20251208_183728.csv\n"
     ]
    }
   ],
   "source": [
    "## Save compliance_matrix to a csv file. The filename should have _date_time appended to it.\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "compliance_matrix.to_csv(f'/Users/adityaponnada/Downloads/time_study_data/compliance_matrix_{current_time}.csv', index=False)\n",
    "print(f\"Compliance matrix saved to /Users/adityaponnada/Downloads/time_study_data/compliance_matrix_{current_time}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc64d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training list saved to /Users/adityaponnada/Downloads/time_study_data/training_list_20251208_183728.txt\n",
      "Holdout list saved to /Users/adityaponnada/Downloads/time_study_data/holdout_list_20251208_183728.txt\n"
     ]
    }
   ],
   "source": [
    "## Write training list and holdout list to separate text files\n",
    "with open(f'/Users/adityaponnada/Downloads/time_study_data/training_list_{current_time}.txt', 'w') as f:\n",
    "    for item in training_list:\n",
    "        f.write(f\"{item}\\n\")\n",
    "print(f\"Training list saved to /Users/adityaponnada/Downloads/time_study_data/training_list_{current_time}.txt\")\n",
    "\n",
    "with open(f'/Users/adityaponnada/Downloads/time_study_data/holdout_list_{current_time}.txt', 'w') as f:\n",
    "    for item in holdout_list:\n",
    "        f.write(f\"{item}\\n\")\n",
    "print(f\"Holdout list saved to /Users/adityaponnada/Downloads/time_study_data/holdout_list_{current_time}.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
