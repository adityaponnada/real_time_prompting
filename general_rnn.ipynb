{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b35c19b",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf50a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries for machine learning and data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc22e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/bin/python\n",
      "sys.version: 3.11.14 (main, Oct  9 2025, 16:16:55) [Clang 17.0.0 (clang-1700.4.4.1)]\n",
      "sys.path (first 8): ['/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages', '/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/setuptools/_vendor']\n",
      "site.getsitepackages(): ['/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages']\n",
      "USER site: /Users/adityaponnada/Library/Python/3.11/lib/python/site-packages\n",
      "find tensorflow spec: ModuleSpec(name='tensorflow', loader=<_frozen_importlib_external.SourceFileLoader object at 0x10058bfd0>, origin='/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/__init__.py', submodule_search_locations=['/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow', '/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/_api/v2'])\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib, site\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.version:\", sys.version)\n",
    "print(\"sys.path (first 8):\", sys.path[:8])\n",
    "print(\"site.getsitepackages():\", getattr(site, 'getsitepackages', lambda: None)())\n",
    "print(\"USER site:\", site.USER_SITE)\n",
    "print(\"find tensorflow spec:\", importlib.util.find_spec('tensorflow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96110db",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8632d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_24.0</th>\n",
       "      <th>wake_day_part_25.0</th>\n",
       "      <th>wake_day_part_26.0</th>\n",
       "      <th>wake_day_part_27.0</th>\n",
       "      <th>wake_day_part_28.0</th>\n",
       "      <th>wake_day_part_29.0</th>\n",
       "      <th>wake_day_part_30.0</th>\n",
       "      <th>wake_day_part_31.0</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrivejanitoruniformly@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrivejanitoruniformly@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180555</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrivejanitoruniformly@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176050</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arrivejanitoruniformly@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172060</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrivejanitoruniformly@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104721</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         participant_id  outcome  is_weekend  \\\n",
       "0  arrivejanitoruniformly@timestudy_com        1           1   \n",
       "1  arrivejanitoruniformly@timestudy_com        1           1   \n",
       "2  arrivejanitoruniformly@timestudy_com        1           1   \n",
       "3  arrivejanitoruniformly@timestudy_com        1           1   \n",
       "4  arrivejanitoruniformly@timestudy_com        1           1   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    NaN              NaN          0        0.000002   \n",
       "1                    0.0              0.0          0        0.000002   \n",
       "2                    NaN              NaN          0        0.000002   \n",
       "3                    NaN              NaN          0        0.000002   \n",
       "4                    NaN              NaN          0        0.000002   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              0.0               0.0                 0.187031  ...   \n",
       "1              0.0               0.0                 0.180555  ...   \n",
       "2              0.0               0.0                 0.176050  ...   \n",
       "3              0.0               0.0                 0.172060  ...   \n",
       "4              0.0               0.0                 0.104721  ...   \n",
       "\n",
       "   wake_day_part_24.0  wake_day_part_25.0  wake_day_part_26.0  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   wake_day_part_27.0  wake_day_part_28.0  wake_day_part_29.0  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   wake_day_part_30.0  wake_day_part_31.0  wake_day_part_32.0  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   wake_day_part_33.0  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset\n",
    "raw_feature_df_scaled = pd.read_csv('/Users/adityaponnada/Downloads/time_study_data/processed_features_v100.csv')\n",
    "## Display the first few rows of the dataset\n",
    "raw_feature_df_scaled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944de75",
   "metadata": {},
   "source": [
    "# Missingness indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a282f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   in_battery_saver_mode  mi_in_battery_saver_mode\n",
       "0                    NaN                         1\n",
       "1                    0.0                         0\n",
       "2                    NaN                         1\n",
       "3                    NaN                         1\n",
       "4                    NaN                         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_missingness_indicators(df, id_col='participant_id', outcome_col='outcome', prefix='mi_'):\n",
    "    \"\"\"\n",
    "    Add binary missingness indicator columns to `df` for every column except the id_col and outcome_col.\n",
    "\n",
    "    Rules:\n",
    "      - Skip columns named by id_col and outcome_col.\n",
    "      - For a column named X, create column named prefix + X (e.g., 'mi_X').\n",
    "      - Indicator is 1 when the original value is NaN, else 0.\n",
    "\n",
    "    The function returns the DataFrame with the new indicator columns added (inplace on a copy).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    if df is None or not hasattr(df, 'copy'):\n",
    "        raise ValueError('df must be a pandas DataFrame')\n",
    "\n",
    "    result = df if df is None else df.copy()\n",
    "    skip = {id_col, outcome_col}\n",
    "    for col in result.columns.tolist():\n",
    "        if col in skip:\n",
    "            continue\n",
    "        # skip already-indicator columns to avoid creating mi_mi_X\n",
    "        if str(col).startswith(prefix):\n",
    "            continue\n",
    "        mi_col = f'{prefix}{col}'\n",
    "        # compute indicator: 1 if NaN, else 0. Use isna for pandas types\n",
    "        try:\n",
    "            result[mi_col] = result[col].isna().astype(int)\n",
    "        except Exception:\n",
    "            # fallback: use pandas isnull\n",
    "            result[mi_col] = pd.isnull(result[col]).astype(int)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "raw_feature_df_scaled = add_missingness_indicators(raw_feature_df_scaled)\n",
    "raw_feature_df_scaled[['in_battery_saver_mode', 'mi_in_battery_saver_mode']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcc731",
   "metadata": {},
   "source": [
    "# Split training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8018dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_by_users_random(df, id_col='participant_id', n_train_users=10, random_state=None):\n",
    "    \"\"\"\n",
    "    Randomly split a DataFrame into a train set containing all rows for a randomly\n",
    "    selected set of `n_train_users` participants and a test set containing the\n",
    "    remaining participants.\n",
    "\n",
    "    Returns: (train_df, test_df) with indices reset.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    if id_col not in df.columns:\n",
    "        raise ValueError(f\"id_col '{id_col}' not found in DataFrame columns\")\n",
    "\n",
    "    unique_ids = pd.Index(df[id_col].dropna().unique())\n",
    "    n_unique = len(unique_ids)\n",
    "    if n_unique == 0:\n",
    "        raise ValueError('No participant ids found in the DataFrame')\n",
    "    if n_train_users <= 0 or n_train_users >= n_unique:\n",
    "        raise ValueError(f'n_train_users must be >0 and < number of unique participants ({n_unique})')\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    train_ids = rng.choice(unique_ids, size=n_train_users, replace=False)\n",
    "\n",
    "    train_df = df[df[id_col].isin(train_ids)].reset_index(drop=True)\n",
    "    test_df = df[~df[id_col].isin(train_ids)].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Example usage:\n",
    "train_df, test_df = split_train_test_by_users_random(raw_feature_df_scaled, n_train_users=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350fda6",
   "metadata": {},
   "source": [
    "# Missing data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2ca39",
   "metadata": {},
   "source": [
    "For features like location, we will use median imputation. For other features we will forward the last known data (using Linear Interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c271597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Missing values per column in train_df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "in_battery_saver_mode    52.497249\n",
       "charging_status          52.497249\n",
       "dist_from_home           12.897827\n",
       "mims_5min                 5.864054\n",
       "is_phone_locked           1.442592\n",
       "                           ...    \n",
       "wake_day_part_12.0        0.000000\n",
       "wake_day_part_11.0        0.000000\n",
       "wake_day_part_10.0        0.000000\n",
       "wake_day_part_9.0         0.000000\n",
       "mi_wake_day_part_33.0     0.000000\n",
       "Length: 122, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the percentage of missing values for each column in train_df\n",
    "missing_pct_train = train_df.isnull().mean() * 100\n",
    "print(\"% Missing values per column in train_df:\")\n",
    "missing_pct_train.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf685b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(train_df, show=True):\n",
    "    \"\"\"\n",
    "    Compute a DataFrame summarizing missing data per column for `train_df` and optionally print it in full.\n",
    "\n",
    "    Returns a pandas DataFrame with columns: 'missing_count' and 'missing_pct' (0-100), sorted by missing_pct desc.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df: pandas DataFrame to analyze\n",
    "    - show: if True, print the full DataFrame without truncation\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if train_df is None or not hasattr(train_df, 'isnull'):\n",
    "        raise ValueError('train_df must be a valid pandas DataFrame')\n",
    "\n",
    "    n_rows = len(train_df)\n",
    "    missing_count = train_df.isnull().sum()\n",
    "    missing_pct = (missing_count / n_rows) * 100 if n_rows > 0 else missing_count * 0.0\n",
    "    df_missing = pd.DataFrame({'missing_count': missing_count, 'missing_pct': missing_pct})\n",
    "    df_missing = df_missing.sort_values('missing_pct', ascending=False)\n",
    "\n",
    "    if show:\n",
    "        # display entire table without truncation\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None):\n",
    "            print(df_missing)\n",
    "\n",
    "    return df_missing\n",
    "\n",
    "# Example usage:\n",
    "# df_missing = missing_values_table(train_df)\n",
    "# or to get the Series of percentages: df_missing['missing_pct']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458f058",
   "metadata": {},
   "source": [
    "## Linear interpolation based impuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4accc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_impute(train_df, cols=None, method='linear', limit_direction='both', axis=0, inplace=False, fill_remaining_with='median'):\n",
    "    \"\"\"\n",
    "    Perform linear-interpolation based imputation on `train_df` for the specified columns.\n",
    "\n",
    "    - train_df: pandas DataFrame\n",
    "    - cols: list of columns to interpolate. If None, numeric columns will be used.\n",
    "    - method: interpolation method passed to pandas.DataFrame.interpolate (default 'linear').\n",
    "    - limit_direction: passed to interpolate (default 'both').\n",
    "    - axis: axis for interpolation (0 for index, 1 for columns).\n",
    "    - inplace: if True, modify train_df in place and return it; otherwise return a copy.\n",
    "    - fill_remaining_with: if 'median', fill remaining NaNs with column median after interpolation;\n",
    "      if 'ffill', use forward-fill then backward-fill; if None, leave NaNs as-is.\n",
    "\n",
    "    Returns the imputed DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    if train_df is None or not hasattr(train_df, 'copy'):\n",
    "        raise ValueError('train_df must be a valid pandas DataFrame')\n",
    "\n",
    "    df = train_df if inplace else train_df.copy()\n",
    "\n",
    "    if cols is None:\n",
    "        # default: numeric columns only\n",
    "        cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    else:\n",
    "        # ensure requested cols exist\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "\n",
    "    if not cols:\n",
    "        # nothing to do\n",
    "        return df\n",
    "\n",
    "    # Interpolate numeric columns\n",
    "    try:\n",
    "        df[cols] = df[cols].interpolate(method=method, limit_direction=limit_direction, axis=axis)\n",
    "    except Exception as e:\n",
    "        print(f'Interpolation failed: {e}; returning original or partially-imputed DataFrame')\n",
    "\n",
    "    # Optionally fill remaining NaNs\n",
    "    if fill_remaining_with == 'median':\n",
    "        for c in cols:\n",
    "            if df[c].isna().any():\n",
    "                try:\n",
    "                    med = df[c].median()\n",
    "                    df[c].fillna(med, inplace=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    elif fill_remaining_with == 'ffill':\n",
    "        df[cols] = df[cols].ffill().bfill()\n",
    "    # if None, leave remaining NaNs as-is\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "train_df = interpolate_impute(train_df, cols=None, method='linear', inplace=True)  # numeric cols only\n",
    "# To operate in-place: interpolate_impute(train_df, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a013cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>mi_wake_day_part_24.0</th>\n",
       "      <th>mi_wake_day_part_25.0</th>\n",
       "      <th>mi_wake_day_part_26.0</th>\n",
       "      <th>mi_wake_day_part_27.0</th>\n",
       "      <th>mi_wake_day_part_28.0</th>\n",
       "      <th>mi_wake_day_part_29.0</th>\n",
       "      <th>mi_wake_day_part_30.0</th>\n",
       "      <th>mi_wake_day_part_31.0</th>\n",
       "      <th>mi_wake_day_part_32.0</th>\n",
       "      <th>mi_wake_day_part_33.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catsupexploitmocker@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.923111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catsupexploitmocker@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.906962</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catsupexploitmocker@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.518333</td>\n",
       "      <td>0.898969</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catsupexploitmocker@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.891005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>catsupexploitmocker@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.883027</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      participant_id  outcome  is_weekend  \\\n",
       "0  catsupexploitmocker@timestudy_com        0           0   \n",
       "1  catsupexploitmocker@timestudy_com        0           0   \n",
       "2  catsupexploitmocker@timestudy_com        0           0   \n",
       "3  catsupexploitmocker@timestudy_com        0           0   \n",
       "4  catsupexploitmocker@timestudy_com        0           0   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              1.0          0        0.000003   \n",
       "1                    0.0              1.0          0        0.000053   \n",
       "2                    0.0              1.0          0        0.000005   \n",
       "3                    0.0              1.0          1        0.000005   \n",
       "4                    0.0              1.0          0        0.000006   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0          0.063333                 0.923111  ...   \n",
       "1              1.0          0.366667                 0.906962  ...   \n",
       "2              1.0          0.518333                 0.898969  ...   \n",
       "3              0.0          0.000000                 0.891005  ...   \n",
       "4              1.0          0.016667                 0.883027  ...   \n",
       "\n",
       "   mi_wake_day_part_24.0  mi_wake_day_part_25.0  mi_wake_day_part_26.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   mi_wake_day_part_27.0  mi_wake_day_part_28.0  mi_wake_day_part_29.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   mi_wake_day_part_30.0  mi_wake_day_part_31.0  mi_wake_day_part_32.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   mi_wake_day_part_33.0  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699067b3",
   "metadata": {},
   "source": [
    "## RNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef80739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]\n",
    "train_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aab53403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations per participant_id:\n",
      "participant_id\n",
      "catsupexploitmocker@timestudy_com          14639\n",
      "certifiedembargobartender@timestudy_com    11555\n",
      "diagramuncoupleoutput@timestudy_com        11802\n",
      "kangaroozodiaccrudeness@timestudy_com       9143\n",
      "predatordebatingpredator@timestudy_com     12507\n",
      "residentselfgutter@timestudy_com           14338\n",
      "retrievergeckoabroad@timestudy_com            55\n",
      "superiorpassablecosmic@timestudy_com       11674\n",
      "urchinvariablytrend@timestudy_com          15868\n",
      "whoeverrelightspookily@timestudy_com        8360\n",
      "obs_len (max observations per participant) = 15868\n"
     ]
    }
   ],
   "source": [
    "## Number of observations per participant\n",
    "# Compute and print the number of observations per participant_id in train_df\n",
    "try:\n",
    "    counts = train_df['participant_id'].value_counts().sort_index()\n",
    "    print('Number of observations per participant_id:')\n",
    "    print(counts.to_string())\n",
    "    # store the maximum count in obs_len\n",
    "    obs_len = int(counts.max()) if not counts.empty else 0\n",
    "    print(f'obs_len (max observations per participant) = {obs_len}')\n",
    "except NameError:\n",
    "    print('train_df is not defined. Run the split to create train_df first.')\n",
    "    obs_len = None\n",
    "except Exception as e:\n",
    "    print('Error computing observation counts:', e)\n",
    "    obs_len = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b8d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_users = train_df['participant_id'].nunique()\n",
    "print(num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d05aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participant_id', 'outcome', 'is_weekend', 'in_battery_saver_mode',\n",
      "       'charging_status', 'screen_on', 'dist_from_home', 'is_phone_locked',\n",
      "       'last_phone_usage', 'closeness_to_sleep_time',\n",
      "       ...\n",
      "       'mi_wake_day_part_24.0', 'mi_wake_day_part_25.0',\n",
      "       'mi_wake_day_part_26.0', 'mi_wake_day_part_27.0',\n",
      "       'mi_wake_day_part_28.0', 'mi_wake_day_part_29.0',\n",
      "       'mi_wake_day_part_30.0', 'mi_wake_day_part_31.0',\n",
      "       'mi_wake_day_part_32.0', 'mi_wake_day_part_33.0'],\n",
      "      dtype='object', length=122)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237c9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns in train_df: 122\n",
      "Number of columns excluding ['participant_id', 'outcome']: 120\n"
     ]
    }
   ],
   "source": [
    "## Print the shape of train_df and count feature columns excluding id/outcome\n",
    "try:\n",
    "    n_cols_total = train_df.shape[1]\n",
    "    print('Total columns in train_df:', n_cols_total)\n",
    "    # define which columns to exclude from feature count\n",
    "    exclude_cols = ['participant_id', 'outcome']\n",
    "    feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "    n_feature_cols = len(feature_cols)\n",
    "    print(f'Number of columns excluding {exclude_cols}: {n_feature_cols}')\n",
    "except NameError:\n",
    "    print('train_df is not defined. Run the split to create train_df first.')\n",
    "    n_feature_cols = None\n",
    "except Exception as e:\n",
    "    print('Error computing column counts:', e)\n",
    "    n_feature_cols = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a63af74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 10 training sequences. Example lengths (first 5): [14639, 11555, 11802, 9143, 12507]\n",
      "Built 90 test sequences. Example lengths (first 5): [10845, 13238, 12257, 12757, 4692]\n",
      "Using MAX_LENGTH = 15868 for padding\n",
      "X_train_padded shape: (10, 15868, 120)\n",
      "Built 90 test sequences. Example lengths (first 5): [10845, 13238, 12257, 12757, 4692]\n",
      "Using MAX_LENGTH = 15868 for padding\n",
      "X_train_padded shape: (10, 15868, 120)\n",
      "X_test_padded shape: (90, 15868, 120)\n",
      "train_mask shape: (10, 15868)\n",
      "test_mask shape: (90, 15868)\n",
      "X_test_padded shape: (90, 15868, 120)\n",
      "train_mask shape: (10, 15868)\n",
      "test_mask shape: (90, 15868)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences for RNN input by building sequences directly from `train_df` / `test_df`.\n",
    "# Assumes `train_df` and optionally `test_df` exist and are already scaled.\n",
    "# We group rows by `participant_id`, collect feature columns (exclude id/outcome),\n",
    "# optionally sort by a timestamp column if present, then pad to obs_len (or inferred).\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "PADDING_VALUE = -999.0\n",
    "ID_COL = 'participant_id'\n",
    "OUTCOME_COL = 'outcome'\n",
    "\n",
    "# Verify train_df exists\n",
    "if 'train_df' not in globals() or train_df is None:\n",
    "    raise RuntimeError('train_df not found. Run the split/preprocessing cells before padding.')\n",
    "\n",
    "# Choose feature columns: all except ID_COL and OUTCOME_COL\n",
    "exclude_cols = {ID_COL, OUTCOME_COL}\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "if not feature_cols:\n",
    "    raise RuntimeError(f'No feature columns found after excluding {exclude_cols}')\n",
    "\n",
    "# If there's a timestamp-like column, use it to sort within each participant\n",
    "timestamp_candidates = ['timestamp','time','start_time','started_at','created_at','event_time']\n",
    "sort_col = next((c for c in timestamp_candidates if c in train_df.columns), None)\n",
    "\n",
    "def _build_sequences_from_df(df):\n",
    "    \"\"\"Return a list of 2D numpy arrays (timesteps x features), one per participant in df.\"\"\"\n",
    "    seqs = []\n",
    "    # group preserves order only if df is already ordered; we'll sort if a sort_col exists\n",
    "    if sort_col is not None:\n",
    "        grouped = df.sort_values(sort_col).groupby(ID_COL, sort=True)\n",
    "    else:\n",
    "        grouped = df.groupby(ID_COL, sort=True)\n",
    "\n",
    "    for pid, group in grouped:\n",
    "        # extract feature columns as a 2D array\n",
    "        arr = group[feature_cols].to_numpy(dtype=np.float32)\n",
    "        seqs.append(arr)\n",
    "    return seqs\n",
    "\n",
    "# Build train sequences\n",
    "X_train_seqs = _build_sequences_from_df(train_df)\n",
    "print(f'Built {len(X_train_seqs)} training sequences. Example lengths (first 5):', [len(s) for s in X_train_seqs[:5]])\n",
    "\n",
    "# Build test sequences if test_df exists\n",
    "X_test_seqs = None\n",
    "if 'test_df' in globals() and test_df is not None:\n",
    "    X_test_seqs = _build_sequences_from_df(test_df)\n",
    "    print(f'Built {len(X_test_seqs)} test sequences. Example lengths (first 5):', [len(s) for s in X_test_seqs[:5]])\n",
    "\n",
    "# Determine MAX_LENGTH: prefer obs_len, else infer from sequences\n",
    "if 'obs_len' in globals() and obs_len is not None and int(obs_len) > 0:\n",
    "    MAX_LENGTH = int(obs_len)\n",
    "else:\n",
    "    all_lengths = [len(s) for s in X_train_seqs]\n",
    "    if X_test_seqs is not None:\n",
    "        all_lengths += [len(s) for s in X_test_seqs]\n",
    "    if not all_lengths:\n",
    "        raise RuntimeError('No sequences found to infer MAX_LENGTH')\n",
    "    MAX_LENGTH = int(max(all_lengths))\n",
    "\n",
    "print(f'Using MAX_LENGTH = {MAX_LENGTH} for padding')\n",
    "\n",
    "# Pad sequences into 3D arrays (n_users, time_steps, n_features)\n",
    "try:\n",
    "    X_train_padded = pad_sequences(X_train_seqs, maxlen=MAX_LENGTH, dtype='float32', padding='post', truncating='post', value=PADDING_VALUE)\n",
    "    print('X_train_padded shape:', X_train_padded.shape)\n",
    "except Exception as e:\n",
    "    X_train_padded = None\n",
    "    print('Failed to pad training sequences:', e)\n",
    "\n",
    "X_test_padded = None\n",
    "if X_test_seqs is not None:\n",
    "    try:\n",
    "        X_test_padded = pad_sequences(X_test_seqs, maxlen=MAX_LENGTH, dtype='float32', padding='post', truncating='post', value=PADDING_VALUE)\n",
    "        print('X_test_padded shape:', X_test_padded.shape)\n",
    "    except Exception as e:\n",
    "        X_test_padded = None\n",
    "        print('Failed to pad test sequences:', e)\n",
    "\n",
    "# Create boolean masks (True = valid timestep)\n",
    "train_mask = None\n",
    "test_mask = None\n",
    "if X_train_padded is not None:\n",
    "    train_mask = np.any(X_train_padded != PADDING_VALUE, axis=-1)\n",
    "    print('train_mask shape:', train_mask.shape)\n",
    "if X_test_padded is not None:\n",
    "    test_mask = np.any(X_test_padded != PADDING_VALUE, axis=-1)\n",
    "    print('test_mask shape:', test_mask.shape)\n",
    "\n",
    "# Expose useful names to the notebook globals\n",
    "# X_train_seqs, X_test_seqs, X_train_padded, X_test_padded, train_mask, test_mask, feature_cols, MAX_LENGTH\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
