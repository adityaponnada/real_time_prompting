{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b35c19b",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf50a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries for machine learning and data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc22e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/bin/python\n",
      "sys.version: 3.11.14 (main, Oct  9 2025, 16:16:55) [Clang 17.0.0 (clang-1700.4.4.1)]\n",
      "sys.path (first 8): ['/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages']\n",
      "site.getsitepackages(): ['/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages']\n",
      "USER site: /Users/adityaponnada/Library/Python/3.11/lib/python/site-packages\n",
      "find tensorflow spec: ModuleSpec(name='tensorflow', loader=<_frozen_importlib_external.SourceFileLoader object at 0x145139690>, origin='/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/__init__.py', submodule_search_locations=['/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow'])\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib, site\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.version:\", sys.version)\n",
    "print(\"sys.path (first 8):\", sys.path[:8])\n",
    "print(\"site.getsitepackages():\", getattr(site, 'getsitepackages', lambda: None)())\n",
    "print(\"USER site:\", site.USER_SITE)\n",
    "print(\"find tensorflow spec:\", importlib.util.find_spec('tensorflow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96110db",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8632d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>mi_wake_day_part_24.0</th>\n",
       "      <th>mi_wake_day_part_25.0</th>\n",
       "      <th>mi_wake_day_part_26.0</th>\n",
       "      <th>mi_wake_day_part_27.0</th>\n",
       "      <th>mi_wake_day_part_28.0</th>\n",
       "      <th>mi_wake_day_part_29.0</th>\n",
       "      <th>mi_wake_day_part_30.0</th>\n",
       "      <th>mi_wake_day_part_31.0</th>\n",
       "      <th>mi_wake_day_part_32.0</th>\n",
       "      <th>mi_wake_day_part_33.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>981.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>973.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>965.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>947.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>936.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "1  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "2  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "3  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "4  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              0.0          0        0.006074   \n",
       "1                    NaN              NaN          0        0.005902   \n",
       "2                    0.0              0.0          0        0.005426   \n",
       "3                    0.0              1.0          0        0.005985   \n",
       "4                    0.0              1.0          0        0.006400   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0              60.0               981.983333  ...   \n",
       "1              1.0              60.0               973.966667  ...   \n",
       "2              1.0              60.0               965.933333  ...   \n",
       "3              1.0              60.0               947.966667  ...   \n",
       "4              1.0              60.0               936.966667  ...   \n",
       "\n",
       "   mi_wake_day_part_24.0  mi_wake_day_part_25.0  mi_wake_day_part_26.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   mi_wake_day_part_27.0  mi_wake_day_part_28.0  mi_wake_day_part_29.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   mi_wake_day_part_30.0  mi_wake_day_part_31.0  mi_wake_day_part_32.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   mi_wake_day_part_33.0  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset\n",
    "raw_feature_df_scaled = pd.read_csv('/Users/adityaponnada/Downloads/time_study_data/processed_features_rnn.csv')\n",
    "## Display the first few rows of the dataset\n",
    "raw_feature_df_scaled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861aec07",
   "metadata": {},
   "source": [
    "### Discard missingness indicators for complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7014689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 52 columns: ['mi_is_weekend', 'mi_screen_on', 'mi_days_in_study', 'mi_completion_24h', 'mi_completion_1h', 'mi_time_between_prompts', 'mi_time_since_last_answered', 'mi_completion_since_wake', 'mi_completion_since_start', 'mi_time_of_day_Afternoon', 'mi_time_of_day_Early Morning', 'mi_time_of_day_Evening', 'mi_time_of_day_Late Night', 'mi_time_of_day_Morning', 'mi_time_of_day_Night', 'mi_location_category_Home', 'mi_location_category_Other', 'mi_location_category_School', 'mi_location_category_Transit', 'mi_location_category_Work', 'mi_wake_day_part_0.0', 'mi_wake_day_part_1.0', 'mi_wake_day_part_2.0', 'mi_wake_day_part_3.0', 'mi_wake_day_part_4.0', 'mi_wake_day_part_5.0', 'mi_wake_day_part_6.0', 'mi_wake_day_part_7.0', 'mi_wake_day_part_8.0', 'mi_wake_day_part_9.0', 'mi_wake_day_part_10.0', 'mi_wake_day_part_11.0', 'mi_wake_day_part_12.0', 'mi_wake_day_part_13.0', 'mi_wake_day_part_15.0', 'mi_wake_day_part_16.0', 'mi_wake_day_part_17.0', 'mi_wake_day_part_18.0', 'mi_wake_day_part_19.0', 'mi_wake_day_part_20.0', 'mi_wake_day_part_22.0', 'mi_wake_day_part_23.0', 'mi_wake_day_part_24.0', 'mi_wake_day_part_25.0', 'mi_wake_day_part_26.0', 'mi_wake_day_part_27.0', 'mi_wake_day_part_28.0', 'mi_wake_day_part_29.0', 'mi_wake_day_part_30.0', 'mi_wake_day_part_31.0', 'mi_wake_day_part_32.0', 'mi_wake_day_part_33.0']\n"
     ]
    }
   ],
   "source": [
    "def drop_zero_mi_columns(df, mi_prefix='mi_', inplace=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Drop missingness-indicator columns whose non-null values are all zero.\n",
    "    - Leaves columns that are entirely NaN.\n",
    "    - Returns a DataFrame (copy by default) with those mi_* columns removed.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    if df is None or not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"df must be a pandas DataFrame\")\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    mi_cols = [c for c in df.columns if str(c).startswith(mi_prefix)]\n",
    "    to_drop = []\n",
    "    for c in mi_cols:\n",
    "        non_null = df[c].dropna()\n",
    "        # drop if there's at least one non-null value and all non-null values equal 0\n",
    "        if len(non_null) > 0 and (non_null == 0).all():\n",
    "            to_drop.append(c)\n",
    "\n",
    "    if to_drop:\n",
    "        if verbose:\n",
    "            print(f\"Dropping {len(to_drop)} columns: {to_drop}\")\n",
    "        df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "raw_feature_df_scaled = drop_zero_mi_columns(raw_feature_df_scaled, mi_prefix='mi_', inplace=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14efb71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "      <th>mi_charging_status</th>\n",
       "      <th>mi_dist_from_home</th>\n",
       "      <th>mi_is_phone_locked</th>\n",
       "      <th>mi_last_phone_usage</th>\n",
       "      <th>mi_closeness_to_sleep_time</th>\n",
       "      <th>mi_closeness_to_wake_time</th>\n",
       "      <th>mi_mims_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>981.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>973.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>965.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>947.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>936.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "1  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "2  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "3  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "4  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              0.0          0        0.006074   \n",
       "1                    NaN              NaN          0        0.005902   \n",
       "2                    0.0              0.0          0        0.005426   \n",
       "3                    0.0              1.0          0        0.005985   \n",
       "4                    0.0              1.0          0        0.006400   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0              60.0               981.983333  ...   \n",
       "1              1.0              60.0               973.966667  ...   \n",
       "2              1.0              60.0               965.933333  ...   \n",
       "3              1.0              60.0               947.966667  ...   \n",
       "4              1.0              60.0               936.966667  ...   \n",
       "\n",
       "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
       "0                   0                   0                         0   \n",
       "1                   0                   0                         1   \n",
       "2                   0                   0                         0   \n",
       "3                   0                   0                         0   \n",
       "4                   0                   0                         0   \n",
       "\n",
       "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
       "0                   0                  0                   0   \n",
       "1                   1                  0                   0   \n",
       "2                   0                  0                   0   \n",
       "3                   0                  0                   0   \n",
       "4                   0                  0                   0   \n",
       "\n",
       "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
       "0                    0                           0                          0   \n",
       "1                    0                           0                          0   \n",
       "2                    0                           0                          0   \n",
       "3                    0                           0                          0   \n",
       "4                    0                           0                          0   \n",
       "\n",
       "   mi_mims_5min  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_feature_df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcc731",
   "metadata": {},
   "source": [
    "# Split training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8018dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_by_users_random(df, id_col='participant_id', n_train_users=10, random_state=None):\n",
    "    \"\"\"\n",
    "    Randomly split a DataFrame into a train set containing all rows for a randomly\n",
    "    selected set of `n_train_users` participants and a test set containing the\n",
    "    remaining participants.\n",
    "\n",
    "    Returns: (train_df, test_df) with indices reset.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    if id_col not in df.columns:\n",
    "        raise ValueError(f\"id_col '{id_col}' not found in DataFrame columns\")\n",
    "\n",
    "    unique_ids = pd.Index(df[id_col].dropna().unique())\n",
    "    n_unique = len(unique_ids)\n",
    "    if n_unique == 0:\n",
    "        raise ValueError('No participant ids found in the DataFrame')\n",
    "    if n_train_users <= 0 or n_train_users >= n_unique:\n",
    "        raise ValueError(f'n_train_users must be >0 and < number of unique participants ({n_unique})')\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    train_ids = rng.choice(unique_ids, size=n_train_users, replace=False)\n",
    "\n",
    "    train_df = df[df[id_col].isin(train_ids)].reset_index(drop=True)\n",
    "    test_df = df[~df[id_col].isin(train_ids)].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Example usage:\n",
    "train_df, test_df = split_train_test_by_users_random(raw_feature_df_scaled, n_train_users=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8e5af9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "      <th>mi_charging_status</th>\n",
       "      <th>mi_dist_from_home</th>\n",
       "      <th>mi_is_phone_locked</th>\n",
       "      <th>mi_last_phone_usage</th>\n",
       "      <th>mi_closeness_to_sleep_time</th>\n",
       "      <th>mi_closeness_to_wake_time</th>\n",
       "      <th>mi_mims_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>828.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>816.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>808.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>773.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "1  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "2  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "3  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "4  bartenderradiatorapplied@timestudy_com        1           1   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    NaN              NaN          1        0.021014   \n",
       "1                    NaN              NaN          1        0.019771   \n",
       "2                    NaN              NaN          1        0.021419   \n",
       "3                    NaN              NaN          1        0.021211   \n",
       "4                    NaN              NaN          0        0.023365   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              NaN               NaN               828.966667  ...   \n",
       "1              NaN               NaN               816.966667  ...   \n",
       "2              NaN               NaN               808.983333  ...   \n",
       "3              NaN               NaN               800.983333  ...   \n",
       "4              NaN               NaN               773.966667  ...   \n",
       "\n",
       "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
       "0                   0                   0                         1   \n",
       "1                   0                   0                         1   \n",
       "2                   0                   0                         1   \n",
       "3                   0                   0                         1   \n",
       "4                   0                   0                         1   \n",
       "\n",
       "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
       "0                   1                  0                   1   \n",
       "1                   1                  0                   1   \n",
       "2                   1                  0                   1   \n",
       "3                   1                  0                   1   \n",
       "4                   1                  0                   1   \n",
       "\n",
       "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
       "0                    1                           0                          0   \n",
       "1                    1                           0                          0   \n",
       "2                    1                           0                          0   \n",
       "3                    1                           0                          0   \n",
       "4                    1                           0                          0   \n",
       "\n",
       "   mi_mims_5min  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350fda6",
   "metadata": {},
   "source": [
    "# Missing data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2ca39",
   "metadata": {},
   "source": [
    "For features like location, we will use median imputation. For other features we will forward the last known data (using Linear Interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c271597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Missing values per column in train_df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "in_battery_saver_mode    52.718143\n",
       "charging_status          52.718143\n",
       "dist_from_home           12.220473\n",
       "is_phone_locked           5.727781\n",
       "last_phone_usage          5.727781\n",
       "                           ...    \n",
       "wake_day_part_3.0         0.000000\n",
       "wake_day_part_4.0         0.000000\n",
       "outcome                   0.000000\n",
       "wake_day_part_6.0         0.000000\n",
       "mi_mims_5min              0.000000\n",
       "Length: 70, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the percentage of missing values for each column in train_df\n",
    "missing_pct_train = train_df.isnull().mean() * 100\n",
    "print(\"% Missing values per column in train_df:\")\n",
    "missing_pct_train.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad284568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print_column_dtypes not defined — printing dtypes and non-null counts directly\n",
      "participant_id                 object\n",
      "outcome                         int64\n",
      "is_weekend                      int64\n",
      "in_battery_saver_mode         float64\n",
      "charging_status               float64\n",
      "                               ...   \n",
      "mi_is_phone_locked              int64\n",
      "mi_last_phone_usage             int64\n",
      "mi_closeness_to_sleep_time      int64\n",
      "mi_closeness_to_wake_time       int64\n",
      "mi_mims_5min                    int64\n",
      "Length: 70, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print column dtypes using helper if available, else fallback to direct printing\n",
    "if 'train_df' not in globals():\n",
    "    print('train_df not found; run the split cell to create it first.')\n",
    "else:\n",
    "    if 'print_column_dtypes' in globals():\n",
    "        print_column_dtypes(train_df, show_counts=True)\n",
    "    else:\n",
    "        print('print_column_dtypes not defined — printing dtypes and non-null counts directly')\n",
    "        print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ac7cb",
   "metadata": {},
   "source": [
    "### Fill forward + hybrid imputation for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de20d5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 60 columns (excluding {'outcome', 'participant_id'} and prefix)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned medians (preview):\n",
      "               is_weekend  in_battery_saver_mode  charging_status  screen_on  \\\n",
      "global_median         0.0                    0.0              0.0        0.0   \n",
      "\n",
      "               dist_from_home  is_phone_locked  last_phone_usage  \\\n",
      "global_median        0.015463              1.0               9.1   \n",
      "\n",
      "               closeness_to_sleep_time  closeness_to_wake_time  mims_5min  \\\n",
      "global_median               464.916667              467.066667  30.571034   \n",
      "\n",
      "               ...  wake_day_part_24.0  wake_day_part_25.0  \\\n",
      "global_median  ...                 0.0                 0.0   \n",
      "\n",
      "               wake_day_part_26.0  wake_day_part_27.0  wake_day_part_28.0  \\\n",
      "global_median                 0.0                 0.0                 0.0   \n",
      "\n",
      "               wake_day_part_29.0  wake_day_part_30.0  wake_day_part_31.0  \\\n",
      "global_median                 0.0                 0.0                 0.0   \n",
      "\n",
      "               wake_day_part_32.0  wake_day_part_33.0  \n",
      "global_median                 0.0                 0.0  \n",
      "\n",
      "[1 rows x 60 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n",
      "/var/folders/h6/3rl340nn7cg92xvwk801_3b80000gn/T/ipykernel_75371/184998816.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  s_filled = s_after_first.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "def impute_group_median_then_ffill(df, id_col='participant_id', outcome_col='outcome', mi_prefix='mi_', inplace=False, verbose=False):\n",
    "    \"\"\"Impute missing values per participant using group medians and forward-fill.\"\"\"\n",
    "    # Steps:\n",
    "    # 1) Group by participant id.\n",
    "    # 2) Ignore columns: id_col, outcome_col, and any column starting with mi_prefix.\n",
    "    # 3) For remaining numeric columns: compute the group's median. If the first value in the\n",
    "    #    group for that column is NaN, replace it with the group's median (fallback to global median if needed).\n",
    "    # 4) For remaining NaNs in the group, use forward-fill (LOCF).\n",
    "    # 5) After group-level processing, compute global medians for the processed columns and return them.\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    if df is None:\n",
    "        raise ValueError('df must be a pandas DataFrame')\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    # Select columns to process (exclude id/outcome/mi_*)\n",
    "    exclude = {id_col, outcome_col}\n",
    "    cols_to_process = [c for c in df.columns if c not in exclude and not str(c).startswith(mi_prefix)]\n",
    "    if verbose:\n",
    "        print(f'Processing {len(cols_to_process)} columns (excluding {exclude} and prefix)')\n",
    "    # Work only on numeric columns for median-based imputation; others we will still forward-fill if needed\n",
    "    numeric_cols = df[cols_to_process].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Compute global medians for numeric columns\n",
    "    global_medians = df[numeric_cols].median() if numeric_cols else pd.Series(dtype=float)\n",
    "    # Group by participant and impute per-group\n",
    "    if id_col in df.columns and numeric_cols:\n",
    "        grouped = df.groupby(id_col, sort=False)\n",
    "        for pid, idx in grouped.groups.items():\n",
    "            for col in numeric_cols:\n",
    "                s = df.loc[idx, col]\n",
    "                # group median (may be NaN if group has no non-NaN values)\n",
    "                try:\n",
    "                    gm = grouped[col].median().get(pid, np.nan) if hasattr(grouped[col], 'median') else np.nan\n",
    "                except Exception:\n",
    "                    gm = np.nan\n",
    "                if pd.isna(gm):\n",
    "                    # fallback to global median if group median not available\n",
    "                    gm = global_medians.get(col, np.nan)\n",
    "                # If first value is NaN, set it to group median (or global median fallback)\n",
    "                if not s.empty and pd.isna(s.iloc[0]):\n",
    "                    if not pd.isna(gm):\n",
    "                        df.loc[idx[0], col] = gm\n",
    "                # Forward-fill within the group for remaining NaNs\n",
    "                # Use transform-style assignment: compute filled series and write back only where original was NaN\n",
    "                s_after_first = df.loc[idx, col]\n",
    "                s_filled = s_after_first.fillna(method='ffill')\n",
    "                mask = s_after_first.isna()\n",
    "                if mask.any():\n",
    "                    df.loc[idx, col] = s_filled\n",
    "    else:\n",
    "        # If id_col not present or no numeric columns, fall back to global strategies\n",
    "        for col in numeric_cols:\n",
    "            # if first value is NaN, replace with global median\n",
    "            if df[col].isna().iloc[0]:\n",
    "                gm = global_medians.get(col, np.nan)\n",
    "                if not pd.isna(gm):\n",
    "                    df.iloc[0, df.columns.get_loc(col)] = gm\n",
    "            # forward-fill the rest\n",
    "            df[col] = df[col].fillna(method='ffill')\n",
    "    # After group-level imputation, any remaining NaNs in numeric_cols -> fill with global medians\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isna().any():\n",
    "            gm = global_medians.get(col, np.nan)\n",
    "            if not pd.isna(gm):\n",
    "                df[col] = df[col].fillna(gm)\n",
    "    # Build medians dataframe to return (global medians for processed numeric columns)\n",
    "    if not numeric_cols:\n",
    "        medians_df = pd.DataFrame()\n",
    "    else:\n",
    "        medians_df = pd.DataFrame(global_medians).T.rename(index={0: 'global_median'})\n",
    "    return df, medians_df\n",
    "\n",
    "# Example usage: apply the imputer to train_df if available\n",
    "if 'train_df' in globals():\n",
    "    train_df, medians = impute_group_median_then_ffill(train_df, verbose=True)\n",
    "    print('Returned medians (preview):')\n",
    "    print(medians.head())\n",
    "else:\n",
    "    print('train_df not found; run the split cell to create it before imputing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98fd9844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "      <th>mi_charging_status</th>\n",
       "      <th>mi_dist_from_home</th>\n",
       "      <th>mi_is_phone_locked</th>\n",
       "      <th>mi_last_phone_usage</th>\n",
       "      <th>mi_closeness_to_sleep_time</th>\n",
       "      <th>mi_closeness_to_wake_time</th>\n",
       "      <th>mi_mims_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>828.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>816.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>808.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>800.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>773.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "1  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "2  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "3  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "4  bartenderradiatorapplied@timestudy_com        1           1   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              0.0          1        0.021014   \n",
       "1                    0.0              0.0          1        0.019771   \n",
       "2                    0.0              0.0          1        0.021419   \n",
       "3                    0.0              0.0          1        0.021211   \n",
       "4                    0.0              0.0          0        0.023365   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0               9.1               828.966667  ...   \n",
       "1              1.0               9.1               816.966667  ...   \n",
       "2              1.0               9.1               808.983333  ...   \n",
       "3              1.0               9.1               800.983333  ...   \n",
       "4              1.0               9.1               773.966667  ...   \n",
       "\n",
       "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
       "0                   0                   0                         1   \n",
       "1                   0                   0                         1   \n",
       "2                   0                   0                         1   \n",
       "3                   0                   0                         1   \n",
       "4                   0                   0                         1   \n",
       "\n",
       "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
       "0                   1                  0                   1   \n",
       "1                   1                  0                   1   \n",
       "2                   1                  0                   1   \n",
       "3                   1                  0                   1   \n",
       "4                   1                  0                   1   \n",
       "\n",
       "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
       "0                    1                           0                          0   \n",
       "1                    1                           0                          0   \n",
       "2                    1                           0                          0   \n",
       "3                    1                           0                          0   \n",
       "4                    1                           0                          0   \n",
       "\n",
       "   mi_mims_5min  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "552c360f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>closeness_to_wake_time</th>\n",
       "      <th>mims_5min</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_24.0</th>\n",
       "      <th>wake_day_part_25.0</th>\n",
       "      <th>wake_day_part_26.0</th>\n",
       "      <th>wake_day_part_27.0</th>\n",
       "      <th>wake_day_part_28.0</th>\n",
       "      <th>wake_day_part_29.0</th>\n",
       "      <th>wake_day_part_30.0</th>\n",
       "      <th>wake_day_part_31.0</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>global_median</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>464.916667</td>\n",
       "      <td>467.066667</td>\n",
       "      <td>30.571034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               is_weekend  in_battery_saver_mode  charging_status  screen_on  \\\n",
       "global_median         0.0                    0.0              0.0        0.0   \n",
       "\n",
       "               dist_from_home  is_phone_locked  last_phone_usage  \\\n",
       "global_median        0.015463              1.0               9.1   \n",
       "\n",
       "               closeness_to_sleep_time  closeness_to_wake_time  mims_5min  \\\n",
       "global_median               464.916667              467.066667  30.571034   \n",
       "\n",
       "               ...  wake_day_part_24.0  wake_day_part_25.0  \\\n",
       "global_median  ...                 0.0                 0.0   \n",
       "\n",
       "               wake_day_part_26.0  wake_day_part_27.0  wake_day_part_28.0  \\\n",
       "global_median                 0.0                 0.0                 0.0   \n",
       "\n",
       "               wake_day_part_29.0  wake_day_part_30.0  wake_day_part_31.0  \\\n",
       "global_median                 0.0                 0.0                 0.0   \n",
       "\n",
       "               wake_day_part_32.0  wake_day_part_33.0  \n",
       "global_median                 0.0                 0.0  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ec89d",
   "metadata": {},
   "source": [
    "## Impute test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a99037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing 60 columns (excluding {'outcome', 'participant_id'} and prefix \"mi_\")\n",
      "Filled 518170 NaNs in column \"in_battery_saver_mode\" with median 0.0\n",
      "Filled 518170 NaNs in column \"charging_status\" with median 0.0\n",
      "Filled 161838 NaNs in column \"dist_from_home\" with median 0.0154626683537372\n",
      "Filled 132247 NaNs in column \"is_phone_locked\" with median 1.0\n",
      "Filled 134667 NaNs in column \"last_phone_usage\" with median 9.1\n",
      "Filled 679 NaNs in column \"closeness_to_sleep_time\" with median 464.9166666666667\n",
      "Filled 679 NaNs in column \"closeness_to_wake_time\" with median 467.06666666666666\n",
      "Filled 50460 NaNs in column \"mims_5min\" with median 30.571034085945772\n",
      "Test set imputation complete. Preview:\n",
      "                           participant_id  outcome  is_weekend  \\\n",
      "0  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
      "1  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
      "2  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
      "3  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
      "4  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
      "\n",
      "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
      "0                    0.0              0.0          0        0.006074   \n",
      "1                    0.0              0.0          0        0.005902   \n",
      "2                    0.0              0.0          0        0.005426   \n",
      "3                    0.0              1.0          0        0.005985   \n",
      "4                    0.0              1.0          0        0.006400   \n",
      "\n",
      "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
      "0              1.0              60.0               981.983333  ...   \n",
      "1              1.0              60.0               973.966667  ...   \n",
      "2              1.0              60.0               965.933333  ...   \n",
      "3              1.0              60.0               947.966667  ...   \n",
      "4              1.0              60.0               936.966667  ...   \n",
      "\n",
      "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
      "0                   0                   0                         0   \n",
      "1                   0                   0                         1   \n",
      "2                   0                   0                         0   \n",
      "3                   0                   0                         0   \n",
      "4                   0                   0                         0   \n",
      "\n",
      "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
      "0                   0                  0                   0   \n",
      "1                   1                  0                   0   \n",
      "2                   0                  0                   0   \n",
      "3                   0                  0                   0   \n",
      "4                   0                  0                   0   \n",
      "\n",
      "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
      "0                    0                           0                          0   \n",
      "1                    0                           0                          0   \n",
      "2                    0                           0                          0   \n",
      "3                    0                           0                          0   \n",
      "4                    0                           0                          0   \n",
      "\n",
      "   mi_mims_5min  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Impute test data using provided medians + forward-fill per participant\n",
    "# ---------------------------------------------------------------------------\n",
    "def impute_test_with_medians_and_ffill(df, medians_df, id_col='participant_id', outcome_col='outcome', mi_prefix='mi_', inplace=False, verbose=False):\n",
    "    \"\"\"Impute missing values in a test DataFrame using a medians DataFrame for first-imputation\n",
    "\n",
    "    For numeric columns present in `medians_df`, any NaN observations in `df` will be\n",
    "    filled with the corresponding median value from `medians_df`. For remaining NaNs\n",
    "    (and for non-numeric columns), imputation within each participant is done with\n",
    "    forward-fill (LOCF). The function groups by `id_col` and performs group-wise\n",
    "    forward-fill so sequence continuity is preserved per participant.\n",
    "\n",
    "    Parameters\n",
    "    - df: pandas.DataFrame (test set)\n",
    "    - medians_df: pandas.DataFrame with column names matching df columns and at least\n",
    "      one row containing medians (e.g., the `medians` returned by the train imputer).\n",
    "    - id_col: column name for participant id (default 'participant_id')\n",
    "    - outcome_col: column name to skip (default 'outcome')\n",
    "    - mi_prefix: prefix for missingness indicator columns to skip (default 'mi_')\n",
    "    - inplace: if False (default) operate on a copy and return it\n",
    "    - verbose: print progress when True\n",
    "\n",
    "    Returns the imputed DataFrame (same shape as input).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    if df is None:\n",
    "        raise ValueError('df must be a pandas DataFrame')\n",
    "    if medians_df is None or medians_df.empty:\n",
    "        raise ValueError('medians_df must be a non-empty DataFrame')\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    # Columns to exclude from imputation\n",
    "    exclude = {id_col, outcome_col}\n",
    "    cols_to_process = [c for c in df.columns if c not in exclude and not str(c).startswith(mi_prefix)]\n",
    "    if verbose:\n",
    "        print(f'Imputing {len(cols_to_process)} columns (excluding {exclude} and prefix \"{mi_prefix}\")')\n",
    "\n",
    "    # Determine medians mapping: flatten medians_df to a single row mapping if needed\n",
    "    # Prefer a column-wise lookup: medians_df may have index like 'global_median'\n",
    "    if medians_df.shape[0] == 1:\n",
    "        med_map = medians_df.iloc[0].to_dict()\n",
    "    else:\n",
    "        # If multiple rows exist, try to find a row named 'global_median', else take first row\n",
    "        if 'global_median' in medians_df.index:\n",
    "            med_map = medians_df.loc['global_median'].to_dict()\n",
    "        else:\n",
    "            med_map = medians_df.iloc[0].to_dict()\n",
    "\n",
    "    # First pass: where df[col] is NaN and med_map has a median, fill with that median\n",
    "    for col in cols_to_process:\n",
    "        if col in med_map and pd.notna(med_map.get(col)):\n",
    "            try:\n",
    "                # only operate on positions that are NaN\n",
    "                mask = df[col].isna()\n",
    "                if mask.any():\n",
    "                    df.loc[mask, col] = med_map.get(col)\n",
    "                    if verbose:\n",
    "                        print(f'Filled {mask.sum()} NaNs in column \"{col}\" with median {med_map.get(col)}')\n",
    "            except KeyError:\n",
    "                # column not present (shouldn't happen since cols_to_process derived from df)\n",
    "                continue\n",
    "\n",
    "    # Second pass: group-wise forward-fill for remaining NaNs (per participant)\n",
    "    if id_col in df.columns:\n",
    "        grouped = df.groupby(id_col, sort=False)\n",
    "        for col in cols_to_process:\n",
    "            # Only proceed if there are NaNs remaining in the column\n",
    "            if not df[col].isna().any():\n",
    "                continue\n",
    "            try:\n",
    "                # Compute a forward-filled series aligned to the original index per group\n",
    "                filled = grouped[col].transform(lambda s: s.fillna(method='ffill'))\n",
    "            except Exception:\n",
    "                # fallback to a global forward-fill if group transform fails\n",
    "                filled = df[col].fillna(method='ffill')\n",
    "\n",
    "            # Only write back values where original was NaN (to avoid overwriting valid data)\n",
    "            mask = df[col].isna()\n",
    "            if mask.any():\n",
    "                df.loc[mask, col] = filled[mask]\n",
    "                if verbose:\n",
    "                    print(f'After group-ffill, filled {mask.sum()} remaining NaNs in column \"{col}\"')\n",
    "    else:\n",
    "        # No participant id column: simple forward-fill across the whole df\n",
    "        for col in cols_to_process:\n",
    "            if df[col].isna().any():\n",
    "                before = df[col].isna().sum()\n",
    "                df[col] = df[col].fillna(method='ffill')\n",
    "                after = df[col].isna().sum()\n",
    "                if verbose:\n",
    "                    print(f'Global ffill {col}: {before-after} values filled')\n",
    "\n",
    "    # Final pass: if any NaNs remain in columns, fill with med_map fallback\n",
    "    for col in cols_to_process:\n",
    "        if df[col].isna().any() and col in med_map and pd.notna(med_map.get(col)):\n",
    "            before = df[col].isna().sum()\n",
    "            df[col] = df[col].fillna(med_map.get(col))\n",
    "            after = df[col].isna().sum()\n",
    "            if verbose:\n",
    "                print(f'Filled {before-after} remaining NaNs in \"{col}\" with median fallback')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage: apply to test_df if medians are available\n",
    "if 'test_df' in globals() and 'medians' in globals():\n",
    "    test_df = impute_test_with_medians_and_ffill(test_df, medians, verbose=True)\n",
    "    print('Test set imputation complete. Preview:')\n",
    "    print(test_df.head())\n",
    "else:\n",
    "    print('test_df or medians not available; run previous cells first to create them.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef47ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "      <th>mi_charging_status</th>\n",
       "      <th>mi_dist_from_home</th>\n",
       "      <th>mi_is_phone_locked</th>\n",
       "      <th>mi_last_phone_usage</th>\n",
       "      <th>mi_closeness_to_sleep_time</th>\n",
       "      <th>mi_closeness_to_wake_time</th>\n",
       "      <th>mi_mims_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>981.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>973.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>965.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>947.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>936.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "1  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "2  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "3  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "4  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              0.0          0        0.006074   \n",
       "1                    0.0              0.0          0        0.005902   \n",
       "2                    0.0              0.0          0        0.005426   \n",
       "3                    0.0              1.0          0        0.005985   \n",
       "4                    0.0              1.0          0        0.006400   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0              60.0               981.983333  ...   \n",
       "1              1.0              60.0               973.966667  ...   \n",
       "2              1.0              60.0               965.933333  ...   \n",
       "3              1.0              60.0               947.966667  ...   \n",
       "4              1.0              60.0               936.966667  ...   \n",
       "\n",
       "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
       "0                   0                   0                         0   \n",
       "1                   0                   0                         1   \n",
       "2                   0                   0                         0   \n",
       "3                   0                   0                         0   \n",
       "4                   0                   0                         0   \n",
       "\n",
       "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
       "0                   0                  0                   0   \n",
       "1                   1                  0                   0   \n",
       "2                   0                  0                   0   \n",
       "3                   0                  0                   0   \n",
       "4                   0                  0                   0   \n",
       "\n",
       "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
       "0                    0                           0                          0   \n",
       "1                    0                           0                          0   \n",
       "2                    0                           0                          0   \n",
       "3                    0                           0                          0   \n",
       "4                    0                           0                          0   \n",
       "\n",
       "   mi_mims_5min  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2380850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>closeness_to_wake_time</th>\n",
       "      <th>mims_5min</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_24.0</th>\n",
       "      <th>wake_day_part_25.0</th>\n",
       "      <th>wake_day_part_26.0</th>\n",
       "      <th>wake_day_part_27.0</th>\n",
       "      <th>wake_day_part_28.0</th>\n",
       "      <th>wake_day_part_29.0</th>\n",
       "      <th>wake_day_part_30.0</th>\n",
       "      <th>wake_day_part_31.0</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>global_median</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>464.916667</td>\n",
       "      <td>467.066667</td>\n",
       "      <td>30.571034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               is_weekend  in_battery_saver_mode  charging_status  screen_on  \\\n",
       "global_median         0.0                    0.0              0.0        0.0   \n",
       "\n",
       "               dist_from_home  is_phone_locked  last_phone_usage  \\\n",
       "global_median        0.015463              1.0               9.1   \n",
       "\n",
       "               closeness_to_sleep_time  closeness_to_wake_time  mims_5min  \\\n",
       "global_median               464.916667              467.066667  30.571034   \n",
       "\n",
       "               ...  wake_day_part_24.0  wake_day_part_25.0  \\\n",
       "global_median  ...                 0.0                 0.0   \n",
       "\n",
       "               wake_day_part_26.0  wake_day_part_27.0  wake_day_part_28.0  \\\n",
       "global_median                 0.0                 0.0                 0.0   \n",
       "\n",
       "               wake_day_part_29.0  wake_day_part_30.0  wake_day_part_31.0  \\\n",
       "global_median                 0.0                 0.0                 0.0   \n",
       "\n",
       "               wake_day_part_32.0  wake_day_part_33.0  \n",
       "global_median                 0.0                 0.0  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a232c13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_weekend', 'in_battery_saver_mode', 'charging_status', 'screen_on',\n",
       "       'dist_from_home', 'is_phone_locked', 'last_phone_usage',\n",
       "       'closeness_to_sleep_time', 'closeness_to_wake_time', 'mims_5min',\n",
       "       'days_in_study', 'completion_24h', 'completion_1h',\n",
       "       'time_between_prompts', 'time_since_last_answered',\n",
       "       'completion_since_wake', 'completion_since_start',\n",
       "       'time_of_day_Afternoon', 'time_of_day_Early Morning',\n",
       "       'time_of_day_Evening', 'time_of_day_Late Night', 'time_of_day_Morning',\n",
       "       'time_of_day_Night', 'location_category_Home',\n",
       "       'location_category_Other', 'location_category_School',\n",
       "       'location_category_Transit', 'location_category_Work',\n",
       "       'wake_day_part_0.0', 'wake_day_part_1.0', 'wake_day_part_2.0',\n",
       "       'wake_day_part_3.0', 'wake_day_part_4.0', 'wake_day_part_5.0',\n",
       "       'wake_day_part_6.0', 'wake_day_part_7.0', 'wake_day_part_8.0',\n",
       "       'wake_day_part_9.0', 'wake_day_part_10.0', 'wake_day_part_11.0',\n",
       "       'wake_day_part_12.0', 'wake_day_part_13.0', 'wake_day_part_15.0',\n",
       "       'wake_day_part_16.0', 'wake_day_part_17.0', 'wake_day_part_18.0',\n",
       "       'wake_day_part_19.0', 'wake_day_part_20.0', 'wake_day_part_22.0',\n",
       "       'wake_day_part_23.0', 'wake_day_part_24.0', 'wake_day_part_25.0',\n",
       "       'wake_day_part_26.0', 'wake_day_part_27.0', 'wake_day_part_28.0',\n",
       "       'wake_day_part_29.0', 'wake_day_part_30.0', 'wake_day_part_31.0',\n",
       "       'wake_day_part_32.0', 'wake_day_part_33.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3261c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote medians to /Users/adityaponnada/Downloads/time_study_data/general_rnn_medians.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "out_path = Path('/Users/adityaponnada/Downloads/time_study_data/general_rnn_medians.csv')\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "if 'medians' in globals() and isinstance(medians, pd.DataFrame) and not medians.empty:\n",
    "    medians.to_csv(out_path, index=True)\n",
    "    print(f'Wrote medians to {out_path}')\n",
    "else:\n",
    "    print('medians DataFrame not found or empty; nothing written.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5b77c3",
   "metadata": {},
   "source": [
    "## Scale features for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc8d358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-normalized columns (per participant): ['dist_from_home', 'last_phone_usage', 'closeness_to_sleep_time', 'closeness_to_wake_time', 'mims_5min', 'completion_24h', 'completion_1h', 'time_between_prompts', 'time_since_last_answered', 'completion_since_wake', 'completion_since_start']\n",
      "Returned global means shape: (1, 11)\n",
      "Applied z-normalization to train_df; preview of means:\n",
      "             dist_from_home  last_phone_usage  closeness_to_sleep_time  \\\n",
      "global_mean       26.758968         20.221428               450.684061   \n",
      "\n",
      "             closeness_to_wake_time  mims_5min  completion_24h  completion_1h  \\\n",
      "global_mean              499.838291  46.112531        0.757542       0.738929   \n",
      "\n",
      "             time_between_prompts  time_since_last_answered  \\\n",
      "global_mean              47.15425                145.570644   \n",
      "\n",
      "             completion_since_wake  completion_since_start  \n",
      "global_mean               0.692321                0.710762  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Z-normalization helper (mean=0, std=1) for selected columns\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def z_normalize_columns(df, cols_to_scale, id_col='participant_id', inplace=False, ddof=0, verbose=False):\n",
    "    \"\"\"Z-normalize specified columns per-participant (grouped by `id_col`).\n",
    "\n",
    "    For each participant, subtract the participant mean and divide by the participant std.\n",
    "    Groups with zero or undefined std use 1.0 to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "      - df_out: DataFrame with the specified columns z-normalized\n",
    "      - means_df: single-row DataFrame containing global means (not grouped by participant)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    if df is None:\n",
    "        raise ValueError('df must be a pandas DataFrame')\n",
    "    if not isinstance(cols_to_scale, (list, tuple)):\n",
    "        raise ValueError('cols_to_scale must be a list or tuple of column names')\n",
    "    if id_col not in df.columns:\n",
    "        raise ValueError(f\"id_col '{id_col}' not found in DataFrame\")\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    # Ensure requested columns exist\n",
    "    cols = [c for c in cols_to_scale if c in df.columns]\n",
    "    missing = [c for c in cols_to_scale if c not in df.columns]\n",
    "    if missing and verbose:\n",
    "        print(f'Warning: the following requested columns were not found and will be skipped: {missing}')\n",
    "\n",
    "    if not cols:\n",
    "        return df, pd.DataFrame()\n",
    "\n",
    "    # Coerce scaling columns to numeric where possible (non-convertible become NaN)\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # Compute global means (single-row) BEFORE normalization so they represent original training means\n",
    "    global_means_series = df[cols].mean()\n",
    "    means_df = pd.DataFrame(global_means_series).T\n",
    "    means_df.index = ['global_mean']\n",
    "    means_df.index.name = None  # keep a simple single-row DF; caller code accepts single-row DF\n",
    "\n",
    "    # Group by participant\n",
    "    grouped = df.groupby(id_col, sort=False)\n",
    "\n",
    "    # Per-row group means and stds (aligned to df index)\n",
    "    group_means_per_row = grouped[cols].transform('mean')\n",
    "    group_stds_per_row = grouped[cols].transform(lambda s: s.std(ddof=ddof))\n",
    "\n",
    "    # Replace zero or NaN std with 1.0 to avoid division by zero\n",
    "    group_stds_per_row = group_stds_per_row.fillna(0.0).replace({0.0: 1.0})\n",
    "\n",
    "    # Perform z-normalization per participant\n",
    "    df.loc[:, cols] = (df[cols] - group_means_per_row) / group_stds_per_row\n",
    "\n",
    "    if verbose:\n",
    "        print('Z-normalized columns (per participant):', cols)\n",
    "        print('Returned global means shape:', means_df.shape)\n",
    "\n",
    "    return df, means_df\n",
    "\n",
    "# Example usage: define the columns to scale and run on train_df if present\n",
    "cols_to_scale = ['dist_from_home', 'last_phone_usage', 'closeness_to_sleep_time', 'closeness_to_wake_time',\n",
    "                 'mims_5min', 'completion_24h', 'completion_1h', 'time_between_prompts',\n",
    "                 'time_since_last_answered', 'completion_since_wake', 'completion_since_start']\n",
    "\n",
    "if 'train_df' in globals():\n",
    "    train_df, global_means = z_normalize_columns(train_df, cols_to_scale, inplace=False, verbose=True)\n",
    "    print('Applied z-normalization to train_df; preview of means:')\n",
    "    print(global_means)\n",
    "else:\n",
    "    print('train_df not available; run split cell first to create train_df.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ab9217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "      <th>mi_charging_status</th>\n",
       "      <th>mi_dist_from_home</th>\n",
       "      <th>mi_is_phone_locked</th>\n",
       "      <th>mi_last_phone_usage</th>\n",
       "      <th>mi_closeness_to_sleep_time</th>\n",
       "      <th>mi_closeness_to_wake_time</th>\n",
       "      <th>mi_mims_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.178787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.178795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.178784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.018522</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.178786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998212</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bartenderradiatorapplied@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.178771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929624</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "1  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "2  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "3  bartenderradiatorapplied@timestudy_com        0           1   \n",
       "4  bartenderradiatorapplied@timestudy_com        1           1   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              0.0          1       -0.178787   \n",
       "1                    0.0              0.0          1       -0.178795   \n",
       "2                    0.0              0.0          1       -0.178784   \n",
       "3                    0.0              0.0          1       -0.178786   \n",
       "4                    0.0              0.0          0       -0.178771   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0               0.0                 1.069253  ...   \n",
       "1              1.0               0.0                 1.038789  ...   \n",
       "2              1.0               0.0                 1.018522  ...   \n",
       "3              1.0               0.0                 0.998212  ...   \n",
       "4              1.0               0.0                 0.929624  ...   \n",
       "\n",
       "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
       "0                   0                   0                         1   \n",
       "1                   0                   0                         1   \n",
       "2                   0                   0                         1   \n",
       "3                   0                   0                         1   \n",
       "4                   0                   0                         1   \n",
       "\n",
       "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
       "0                   1                  0                   1   \n",
       "1                   1                  0                   1   \n",
       "2                   1                  0                   1   \n",
       "3                   1                  0                   1   \n",
       "4                   1                  0                   1   \n",
       "\n",
       "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
       "0                    1                           0                          0   \n",
       "1                    1                           0                          0   \n",
       "2                    1                           0                          0   \n",
       "3                    1                           0                          0   \n",
       "4                    1                           0                          0   \n",
       "\n",
       "   mi_mims_5min  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3e08f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>closeness_to_wake_time</th>\n",
       "      <th>mims_5min</th>\n",
       "      <th>completion_24h</th>\n",
       "      <th>completion_1h</th>\n",
       "      <th>time_between_prompts</th>\n",
       "      <th>time_since_last_answered</th>\n",
       "      <th>completion_since_wake</th>\n",
       "      <th>completion_since_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>global_mean</th>\n",
       "      <td>26.758968</td>\n",
       "      <td>20.221428</td>\n",
       "      <td>450.684061</td>\n",
       "      <td>499.838291</td>\n",
       "      <td>46.112531</td>\n",
       "      <td>0.757542</td>\n",
       "      <td>0.738929</td>\n",
       "      <td>47.15425</td>\n",
       "      <td>145.570644</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.710762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dist_from_home  last_phone_usage  closeness_to_sleep_time  \\\n",
       "global_mean       26.758968         20.221428               450.684061   \n",
       "\n",
       "             closeness_to_wake_time  mims_5min  completion_24h  completion_1h  \\\n",
       "global_mean              499.838291  46.112531        0.757542       0.738929   \n",
       "\n",
       "             time_between_prompts  time_since_last_answered  \\\n",
       "global_mean              47.15425                145.570644   \n",
       "\n",
       "             completion_since_wake  completion_since_start  \n",
       "global_mean               0.692321                0.710762  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca2ce446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote global_means to /Users/adityaponnada/Downloads/time_study_data/global_means_general_rnn.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Write global_means (from training z-normalization) to CSV for later reuse\n",
    "out_path = Path('/Users/adityaponnada/Downloads/time_study_data/global_means_general_rnn.csv')\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if 'global_means' in globals():\n",
    "    gm = global_means\n",
    "    # Accept Series or DataFrame; convert Series -> single-row DataFrame for consistent saving\n",
    "    if isinstance(gm, pd.Series):\n",
    "        gm_df = gm.to_frame().T\n",
    "    elif isinstance(gm, pd.DataFrame):\n",
    "        gm_df = gm.copy()\n",
    "    else:\n",
    "        print('global_means exists but is not a pandas Series/DataFrame; not written.')\n",
    "        gm_df = None\n",
    "\n",
    "    if gm_df is not None and not gm_df.empty:\n",
    "        gm_df.to_csv(out_path, index=True)\n",
    "        print(f'Wrote global_means to {out_path}')\n",
    "    else:\n",
    "        print('global_means found but empty; nothing written.')\n",
    "else:\n",
    "    print('global_means not found in the notebook namespace; run the training scaling cell first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36706a6f",
   "metadata": {},
   "source": [
    "## Scale features for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83caa622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed z-normalization of test data for columns: ['dist_from_home', 'last_phone_usage', 'closeness_to_sleep_time', 'closeness_to_wake_time', 'mims_5min', 'completion_24h', 'completion_1h', 'time_between_prompts', 'time_since_last_answered', 'completion_since_wake', 'completion_since_start']\n",
      "Scaled test_df preview:\n",
      "   last_phone_usage  closeness_to_sleep_time  closeness_to_wake_time  \\\n",
      "0          1.864088                 2.017567               -1.865121   \n",
      "1          1.864088                 1.987124               -1.834719   \n",
      "2          1.864088                 1.956618               -1.804255   \n",
      "3          1.864088                 1.888391               -1.736120   \n",
      "4          1.864088                 1.846619               -1.694405   \n",
      "\n",
      "   mims_5min  completion_24h  completion_1h  time_between_prompts  \\\n",
      "0  -0.706761      -13.933019      -4.140509             -0.174017   \n",
      "1  -0.373796      -13.933019      -4.140509             -0.144432   \n",
      "2  -0.803382       -4.736813      -1.338812             -0.144371   \n",
      "3  -0.785871       -1.671412      -0.404913             -0.107713   \n",
      "4  -0.802610       -4.736813      -1.338812             -0.133423   \n",
      "\n",
      "   time_since_last_answered  completion_since_wake  completion_since_start  \n",
      "0                 -0.535136              -4.743699               -4.953519  \n",
      "1                 -0.535136              -4.743699               -4.953519  \n",
      "2                 -0.505604              -1.317761               -1.468864  \n",
      "3                 -0.469088              -0.175782               -0.307313  \n",
      "4                 -0.428651              -1.317761               -1.468864  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Z-normalize test data using global means (train) and per-participant std\n",
    "# Only scale a fixed set of allowed columns to avoid accidental scaling elsewhere\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def z_normalize_test_using_global_mean(df, global_means_df, cols_to_scale=None, id_col='participant_id', ddof=0, inplace=False, verbose=False):\n",
    "    \"\"\"Z-normalize selected columns in `df` for test data.\n",
    "\n",
    "    Behavior:\n",
    "    - Centers each column using the mean provided in `global_means_df` (train global means).\n",
    "    - Scales by the per-participant standard deviation computed on `df` (fallbacks used when needed).\n",
    "    - Grouped by `id_col` so scaling preserves per-participant time-series structure.\n",
    "    - Only a predetermined set of allowed columns will be scaled regardless of input.\n",
    "\n",
    "    Returns the scaled DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    if df is None:\n",
    "        raise ValueError('df must be a pandas DataFrame')\n",
    "    if global_means_df is None or global_means_df.empty:\n",
    "        raise ValueError('global_means_df must be a non-empty DataFrame containing training means')\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    # Strict allowed columns (per your request)\n",
    "    allowed_cols = ['dist_from_home', 'last_phone_usage', 'closeness_to_sleep_time', 'closeness_to_wake_time',\n",
    "                    'mims_5min', 'completion_24h', 'completion_1h', 'time_between_prompts',\n",
    "                    'time_since_last_answered', 'completion_since_wake', 'completion_since_start']\n",
    "\n",
    "    # Resolve global means mapping (accept single-row DataFrame or index 'global_mean')\n",
    "    if global_means_df.shape[0] == 1:\n",
    "        gm_map = global_means_df.iloc[0].to_dict()\n",
    "    else:\n",
    "        if 'global_mean' in global_means_df.index:\n",
    "            gm_map = global_means_df.loc['global_mean'].to_dict()\n",
    "        else:\n",
    "            gm_map = global_means_df.iloc[0].to_dict()\n",
    "\n",
    "    # Determine which columns to operate on: intersect provided list (if any) with allowed_cols\n",
    "    if cols_to_scale is None:\n",
    "        requested = allowed_cols\n",
    "    else:\n",
    "        requested = list(cols_to_scale)\n",
    "\n",
    "    cols = [c for c in requested if c in df.columns and c in allowed_cols]\n",
    "    missing = [c for c in allowed_cols if c not in df.columns]\n",
    "    if missing and verbose:\n",
    "        print(f'Allowed columns not present in df and skipped: {missing}')\n",
    "    if not cols:\n",
    "        if verbose:\n",
    "            print('No allowed columns found in DataFrame; returning original df')\n",
    "        return df\n",
    "\n",
    "    # Coerce to numeric where appropriate\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # Compute per-participant stds for the selected columns\n",
    "    if id_col in df.columns:\n",
    "        part_std = df.groupby(id_col)[cols].std(ddof=ddof)\n",
    "    else:\n",
    "        part_std = pd.DataFrame()\n",
    "\n",
    "    # Overall fallback stds computed on df\n",
    "    overall_std = df[cols].std(ddof=ddof)\n",
    "\n",
    "    # Apply scaling per participant\n",
    "    if id_col in df.columns:\n",
    "        grouped = df.groupby(id_col, sort=False)\n",
    "        for pid, idx in grouped.groups.items():\n",
    "            # for this participant, get stds row (may be missing or NaN)\n",
    "            if pid in part_std.index:\n",
    "                stds_row = part_std.loc[pid]\n",
    "            else:\n",
    "                stds_row = pd.Series({c: np.nan for c in cols})\n",
    "\n",
    "            for col in cols:\n",
    "                gm = gm_map.get(col, np.nan)\n",
    "                if pd.isna(gm):\n",
    "                    # if no global mean available, fallback to column mean from df\n",
    "                    gm = df[col].mean()\n",
    "                    if verbose:\n",
    "                        print(f'Global mean for {col} not found; using test-set mean {gm:.4f} as fallback')\n",
    "\n",
    "                std_val = stds_row.get(col, np.nan)\n",
    "                if pd.isna(std_val) or std_val == 0:\n",
    "                    std_val = overall_std.get(col, np.nan)\n",
    "                if pd.isna(std_val) or std_val == 0:\n",
    "                    std_val = 1.0\n",
    "\n",
    "                # Apply z-normalization for this participant and column\n",
    "                try:\n",
    "                    df.loc[idx, col] = (df.loc[idx, col] - gm) / std_val\n",
    "                except Exception:\n",
    "                    # fallback: vectorized operation ensures alignment by index\n",
    "                    col_vals = df.loc[idx, col].to_numpy(dtype=float)\n",
    "                    df.loc[idx, col] = (col_vals - gm) / std_val\n",
    "    else:\n",
    "        # No participant id: apply global centering with gm_map and overall std\n",
    "        for col in cols:\n",
    "            gm = gm_map.get(col, np.nan)\n",
    "            if pd.isna(gm):\n",
    "                gm = df[col].mean()\n",
    "            std_val = overall_std.get(col, np.nan)\n",
    "            if pd.isna(std_val) or std_val == 0:\n",
    "                std_val = 1.0\n",
    "            df[col] = (df[col] - gm) / std_val\n",
    "\n",
    "    if verbose:\n",
    "        print('Completed z-normalization of test data for columns:', cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage (if global_means and test_df exist):\n",
    "if 'test_df' in globals() and 'global_means' in globals():\n",
    "    test_df = z_normalize_test_using_global_mean(test_df, global_means, cols_to_scale=None, verbose=True)\n",
    "    print('Scaled test_df preview:')\n",
    "    print(test_df[[c for c in ['distance_from_home', 'last_phone_usage', 'closeness_to_sleep_time', 'closeness_to_wake_time', 'mims_5min', 'completion_24h', 'completion_1h', 'time_between_prompts', 'time_since_last_answered', 'completion_since_wake', 'completion_since_start'] if c in test_df.columns]].head())\n",
    "else:\n",
    "    print('test_df or global_means not found; run previous cells to produce them before scaling test data.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41858ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>in_battery_saver_mode</th>\n",
       "      <th>charging_status</th>\n",
       "      <th>screen_on</th>\n",
       "      <th>dist_from_home</th>\n",
       "      <th>is_phone_locked</th>\n",
       "      <th>last_phone_usage</th>\n",
       "      <th>closeness_to_sleep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>wake_day_part_32.0</th>\n",
       "      <th>wake_day_part_33.0</th>\n",
       "      <th>mi_in_battery_saver_mode</th>\n",
       "      <th>mi_charging_status</th>\n",
       "      <th>mi_dist_from_home</th>\n",
       "      <th>mi_is_phone_locked</th>\n",
       "      <th>mi_last_phone_usage</th>\n",
       "      <th>mi_closeness_to_sleep_time</th>\n",
       "      <th>mi_closeness_to_wake_time</th>\n",
       "      <th>mi_mims_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.791324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.864088</td>\n",
       "      <td>2.017567</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.791336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.864088</td>\n",
       "      <td>1.987124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.791367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.864088</td>\n",
       "      <td>1.956618</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.791330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.864088</td>\n",
       "      <td>1.888391</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afflictedrevenueepilepsy@timestudy_com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.791302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.864088</td>\n",
       "      <td>1.846619</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           participant_id  outcome  is_weekend  \\\n",
       "0  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "1  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "2  afflictedrevenueepilepsy@timestudy_com        1           0   \n",
       "3  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "4  afflictedrevenueepilepsy@timestudy_com        0           0   \n",
       "\n",
       "   in_battery_saver_mode  charging_status  screen_on  dist_from_home  \\\n",
       "0                    0.0              0.0          0       -1.791324   \n",
       "1                    0.0              0.0          0       -1.791336   \n",
       "2                    0.0              0.0          0       -1.791367   \n",
       "3                    0.0              1.0          0       -1.791330   \n",
       "4                    0.0              1.0          0       -1.791302   \n",
       "\n",
       "   is_phone_locked  last_phone_usage  closeness_to_sleep_time  ...  \\\n",
       "0              1.0          1.864088                 2.017567  ...   \n",
       "1              1.0          1.864088                 1.987124  ...   \n",
       "2              1.0          1.864088                 1.956618  ...   \n",
       "3              1.0          1.864088                 1.888391  ...   \n",
       "4              1.0          1.864088                 1.846619  ...   \n",
       "\n",
       "   wake_day_part_32.0  wake_day_part_33.0  mi_in_battery_saver_mode  \\\n",
       "0                   0                   0                         0   \n",
       "1                   0                   0                         1   \n",
       "2                   0                   0                         0   \n",
       "3                   0                   0                         0   \n",
       "4                   0                   0                         0   \n",
       "\n",
       "   mi_charging_status  mi_dist_from_home  mi_is_phone_locked  \\\n",
       "0                   0                  0                   0   \n",
       "1                   1                  0                   0   \n",
       "2                   0                  0                   0   \n",
       "3                   0                  0                   0   \n",
       "4                   0                  0                   0   \n",
       "\n",
       "   mi_last_phone_usage  mi_closeness_to_sleep_time  mi_closeness_to_wake_time  \\\n",
       "0                    0                           0                          0   \n",
       "1                    0                           0                          0   \n",
       "2                    0                           0                          0   \n",
       "3                    0                           0                          0   \n",
       "4                    0                           0                          0   \n",
       "\n",
       "   mi_mims_5min  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699067b3",
   "metadata": {},
   "source": [
    "## RNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aab53403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations per participant_id:\n",
      "participant_id\n",
      "bartenderradiatorapplied@timestudy_com      4692\n",
      "brinkaminounframed@timestudy_com           11267\n",
      "defilinganywayimmovable@timestudy_com       8060\n",
      "headwearskirmishantidote@timestudy_com     15798\n",
      "pettytransfixedsolubly@timestudy_com        4751\n",
      "remoldexcludingaffair@timestudy_com         6426\n",
      "retrialgraftedsturdy@timestudy_com          3707\n",
      "superiorpassablecosmic@timestudy_com       11674\n",
      "urchinvariablytrend@timestudy_com          15868\n",
      "washboardceramicsenticing@timestudy_com    11755\n",
      "obs_len (max observations per participant) = 15868\n"
     ]
    }
   ],
   "source": [
    "## Number of observations per participant\n",
    "# Compute and print the number of observations per participant_id in train_df\n",
    "try:\n",
    "    counts = train_df['participant_id'].value_counts().sort_index()\n",
    "    print('Number of observations per participant_id:')\n",
    "    print(counts.to_string())\n",
    "    # store the maximum count in obs_len\n",
    "    obs_len = int(counts.max()) if not counts.empty else 0\n",
    "    print(f'obs_len (max observations per participant) = {obs_len}')\n",
    "except NameError:\n",
    "    print('train_df is not defined. Run the split to create train_df first.')\n",
    "    obs_len = None\n",
    "except Exception as e:\n",
    "    print('Error computing observation counts:', e)\n",
    "    obs_len = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b8d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_users = train_df['participant_id'].nunique()\n",
    "print(num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d05aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participant_id', 'outcome', 'is_weekend', 'in_battery_saver_mode',\n",
      "       'charging_status', 'screen_on', 'dist_from_home', 'is_phone_locked',\n",
      "       'last_phone_usage', 'closeness_to_sleep_time', 'closeness_to_wake_time',\n",
      "       'mims_5min', 'days_in_study', 'completion_24h', 'completion_1h',\n",
      "       'time_between_prompts', 'time_since_last_answered',\n",
      "       'completion_since_wake', 'completion_since_start',\n",
      "       'time_of_day_Afternoon', 'time_of_day_Early Morning',\n",
      "       'time_of_day_Evening', 'time_of_day_Late Night', 'time_of_day_Morning',\n",
      "       'time_of_day_Night', 'location_category_Home',\n",
      "       'location_category_Other', 'location_category_School',\n",
      "       'location_category_Transit', 'location_category_Work',\n",
      "       'wake_day_part_0.0', 'wake_day_part_1.0', 'wake_day_part_2.0',\n",
      "       'wake_day_part_3.0', 'wake_day_part_4.0', 'wake_day_part_5.0',\n",
      "       'wake_day_part_6.0', 'wake_day_part_7.0', 'wake_day_part_8.0',\n",
      "       'wake_day_part_9.0', 'wake_day_part_10.0', 'wake_day_part_11.0',\n",
      "       'wake_day_part_12.0', 'wake_day_part_13.0', 'wake_day_part_15.0',\n",
      "       'wake_day_part_16.0', 'wake_day_part_17.0', 'wake_day_part_18.0',\n",
      "       'wake_day_part_19.0', 'wake_day_part_20.0', 'wake_day_part_22.0',\n",
      "       'wake_day_part_23.0', 'wake_day_part_24.0', 'wake_day_part_25.0',\n",
      "       'wake_day_part_26.0', 'wake_day_part_27.0', 'wake_day_part_28.0',\n",
      "       'wake_day_part_29.0', 'wake_day_part_30.0', 'wake_day_part_31.0',\n",
      "       'wake_day_part_32.0', 'wake_day_part_33.0', 'mi_in_battery_saver_mode',\n",
      "       'mi_charging_status', 'mi_dist_from_home', 'mi_is_phone_locked',\n",
      "       'mi_last_phone_usage', 'mi_closeness_to_sleep_time',\n",
      "       'mi_closeness_to_wake_time', 'mi_mims_5min'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "237c9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns in train_df: 70\n",
      "Number of columns excluding ['participant_id', 'outcome']: 68\n"
     ]
    }
   ],
   "source": [
    "## Print the shape of train_df and count feature columns excluding id/outcome\n",
    "try:\n",
    "    n_cols_total = train_df.shape[1]\n",
    "    print('Total columns in train_df:', n_cols_total)\n",
    "    # define which columns to exclude from feature count\n",
    "    exclude_cols = ['participant_id', 'outcome']\n",
    "    feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "    n_feature_cols = len(feature_cols)\n",
    "    print(f'Number of columns excluding {exclude_cols}: {n_feature_cols}')\n",
    "except NameError:\n",
    "    print('train_df is not defined. Run the split to create train_df first.')\n",
    "    n_feature_cols = None\n",
    "except Exception as e:\n",
    "    print('Error computing column counts:', e)\n",
    "    n_feature_cols = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f053148",
   "metadata": {},
   "source": [
    "## Chunked GTCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75c642",
   "metadata": {},
   "source": [
    "Steps are: 1) data preperation, ID mapping, and chunking 2) custom loss functions and metrics function 3) GTCN architecture and training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e93b0",
   "metadata": {},
   "source": [
    "### Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f672eb",
   "metadata": {},
   "source": [
    "Set up constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9eceb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# --- 1. Global Parameters (Aligned to Memory Constraints) ---\n",
    "# L_max observed in your data that caused the ValueError\n",
    "MAX_TIME_SLOTS = obs_len \n",
    "L_CHUNK = 3967 # Aligned chunk length (15868 / 4)\n",
    "NUM_CHUNKS = 4 \n",
    "N_TRAIN = 10 \n",
    "N_TEST = 90\n",
    "NUM_FEATURES = n_feature_cols\n",
    "SENTINEL_VALUE = 999.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c00ff",
   "metadata": {},
   "source": [
    "Add padding ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68b1a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_pad(df, max_len, x_pad_val, y_pad_val, n_feature_cols):\n",
    "    grouped = df.groupby('participant_id')\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    participant_ids = [] # List to store IDs in order\n",
    "    \n",
    "    for participant_id, group in grouped:\n",
    "        participant_ids.append(participant_id) # Save the ID\n",
    "        \n",
    "        X_seq = group.drop(columns=['participant_id', 'outcome']).values \n",
    "        X_list.append(X_seq)\n",
    "        \n",
    "        Y_seq = group['outcome'].values.astype('float16').reshape(-1, 1) \n",
    "        Y_list.append(Y_seq)\n",
    "\n",
    "    # Pad X sequences with float16\n",
    "    X_padded = pad_sequences(X_list, maxlen=max_len, padding='post', value=x_pad_val, dtype='float16')\n",
    "    # Pad Y sequences with float16\n",
    "    Y_padded = pad_sequences(Y_list, maxlen=max_len, padding='post', value=y_pad_val, dtype='float16')\n",
    "    \n",
    "    return X_padded, Y_padded, participant_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d51c9e",
   "metadata": {},
   "source": [
    "Final chunking ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a3bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Data Shape: (10, 15868, 68)\n",
      "Chunked Data Shape: (10, 4, 3967, 68)\n",
      "Train IDs collected: 10\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Reshape Function (Crucial for Chunking) ---\n",
    "def reshape_to_chunks(X_padded, Y_padded, n_users, n_chunks, l_chunk, n_features):\n",
    "    \"\"\"Transforms 3D padded tensors (N, L_max, D) into 4D chunked tensors (N, N_chunks, L_chunk, D).\"\"\"\n",
    "    \n",
    "    # Reshape Features (10, 4, 3967, 120)\n",
    "    X_chunked = X_padded.reshape(n_users, n_chunks, l_chunk, n_features)\n",
    "    \n",
    "    # Reshape Targets (10, 4, 3967, 1)\n",
    "    Y_chunked = Y_padded.reshape(n_users, n_chunks, l_chunk, 1)\n",
    "    \n",
    "    return X_chunked, Y_chunked\n",
    "\n",
    "\n",
    "# --- 5. Execution ---\n",
    "X_train_padded, Y_train_padded, train_user_ids = process_and_pad(\n",
    "    train_df, MAX_TIME_SLOTS, SENTINEL_VALUE, SENTINEL_VALUE, NUM_FEATURES\n",
    ")\n",
    "X_test_padded, Y_test_padded, test_user_ids = process_and_pad(\n",
    "    test_df, MAX_TIME_SLOTS, SENTINEL_VALUE, SENTINEL_VALUE, NUM_FEATURES\n",
    ")\n",
    "\n",
    "# FINAL DATA STRUCTURES FOR TRAINING:\n",
    "X_train_chunked, Y_train_chunked = reshape_to_chunks(\n",
    "    X_train_padded, Y_train_padded, N_TRAIN, NUM_CHUNKS, L_CHUNK, NUM_FEATURES\n",
    ")\n",
    "X_test_chunked, Y_test_chunked = reshape_to_chunks(\n",
    "    X_test_padded, Y_test_padded, N_TEST, NUM_CHUNKS, L_CHUNK, NUM_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Padded Data Shape: {X_train_padded.shape}\")\n",
    "print(f\"Chunked Data Shape: {X_train_chunked.shape}\")\n",
    "print(f\"Train IDs collected: {len(train_user_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a148c51",
   "metadata": {},
   "source": [
    "### Custom loss and metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df14d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# --- CLASS WEIGHTS DEFINED (80% Positive / 20% Negative) ---\n",
    "# W0 = Weight for Negative Class (0) -> Minority (20%) -> Penalty: 0.8\n",
    "# W1 = Weight for Positive Class (1) -> Majority (80%) -> Penalty: 0.2\n",
    "CLASS_WEIGHTS = tf.constant([0.8, 0.2], dtype=tf.float32)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Custom Masked Loss Function (FIXES NaN ERROR AND INCLUDES WEIGHTS)\n",
    "# ---------------------------------------------------\n",
    "## @tf.function # Speed boost: Compiles the loss into a static graph\n",
    "def custom_masked_bce(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Binary Cross-Entropy, applying class weights, ignoring \n",
    "    padded steps (999.0), and using explicit clamping for NaN prevention.\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    # Use multiplication instead of masking to keep shapes static\n",
    "    mask = tf.cast(tf.not_equal(y_true, SENTINEL_VALUE), tf.float32)\n",
    "    y_pred_safe = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
    "    \n",
    "    # Standard BCE\n",
    "    bce = - (y_true * K.log(y_pred_safe) + (1.0 - y_true) * K.log(1.0 - y_pred_safe))\n",
    "    \n",
    "    # Weighting\n",
    "    y_true_int = tf.cast(tf.squeeze(y_true, axis=-1), tf.int32)\n",
    "    # Handle sentinel values in weights by clipping to valid indices\n",
    "    y_true_clipped = tf.clip_by_value(y_true_int, 0, 1)\n",
    "    sample_weights = K.gather(CLASS_WEIGHTS, y_true_clipped)\n",
    "    sample_weights = tf.expand_dims(sample_weights, axis=-1)\n",
    "    \n",
    "    weighted_bce = bce * sample_weights * mask\n",
    "    return tf.reduce_sum(weighted_bce) / (tf.reduce_sum(mask) + K.epsilon())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Custom Masked F1-Score (Metrics)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def masked_precision(y_true, y_pred):\n",
    "    \"\"\"Calculates Precision, ignoring padded steps (999.0).\"\"\"\n",
    "    \n",
    "    # 1. Remove Padding\n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true_flat, SENTINEL_VALUE), tf.bool)\n",
    "    y_true_real = tf.boolean_mask(y_true_flat, mask)\n",
    "    y_pred_real = tf.boolean_mask(y_pred_flat, mask)\n",
    "    y_pred_binary = K.round(y_pred_real)\n",
    "\n",
    "    # 2. INVERSION LOGIC: Transform 0s into 1s to target the negative class\n",
    "    y_true_inv = 1.0 - tf.cast(y_true_real, tf.float32)\n",
    "    y_pred_inv = 1.0 - tf.cast(y_pred_binary, tf.float32)\n",
    "\n",
    "    # 3. Calculate True Positives for Class 0\n",
    "    tp_0 = K.sum(K.round(K.clip(y_true_inv * y_pred_inv, 0, 1)))\n",
    "    pred_pos_0 = K.sum(y_pred_inv)\n",
    "    \n",
    "    return tp_0 / (pred_pos_0 + K.epsilon())\n",
    "\n",
    "def masked_recall(y_true, y_pred):\n",
    "    \"\"\"Calculates Recall, ignoring padded steps (999.0).\"\"\"\n",
    "    \n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true_flat, SENTINEL_VALUE), tf.bool)\n",
    "    y_true_real = tf.boolean_mask(y_true_flat, mask)\n",
    "    y_pred_real = tf.boolean_mask(y_pred_flat, mask)\n",
    "    y_pred_binary = K.round(y_pred_real)\n",
    "\n",
    "    # 2. INVERSION LOGIC\n",
    "    y_true_inv = 1.0 - tf.cast(y_true_real, tf.float32)\n",
    "    y_pred_inv = 1.0 - tf.cast(y_pred_binary, tf.float32)\n",
    "\n",
    "    # 3. Calculate Recall for Class 0\n",
    "    tp_0 = K.sum(K.round(K.clip(y_true_inv * y_pred_inv, 0, 1)))\n",
    "    actual_pos_0 = K.sum(y_true_inv)\n",
    "    \n",
    "    return tp_0 / (actual_pos_0 + K.epsilon())\n",
    "\n",
    "def masked_f1_score(y_true, y_pred):\n",
    "    \"\"\"Calculates F1-Score using masked Precision and Recall.\"\"\"\n",
    "    p = masked_precision(y_true, y_pred)\n",
    "    r = masked_recall(y_true, y_pred)\n",
    "    \n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "## @tf.function\n",
    "def masked_f1_class0(y_true, y_pred):\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    # Static Shape Masking\n",
    "    mask = tf.cast(tf.not_equal(y_true, SENTINEL_VALUE), tf.float32)\n",
    "    \n",
    "    # Invert logic for Class 0 (1.0 - y)\n",
    "    y_t = (1.0 - y_true) * mask\n",
    "    y_p = (1.0 - K.round(y_pred)) * mask\n",
    "    \n",
    "    tp = K.sum(y_t * y_p)\n",
    "    fp = K.sum((1.0 - y_t) * y_p * mask)\n",
    "    fn = K.sum(y_t * (1.0 - y_p) * mask)\n",
    "    \n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f446af",
   "metadata": {},
   "source": [
    "Alternative optimized loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60ef9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STABILITY MODE] Disabling GPU to prevent Metal compilation hangs...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "\n",
    "USE_CPU_ONLY = True \n",
    "\n",
    "if USE_CPU_ONLY:\n",
    "    print(\"\\n[STABILITY MODE] Disabling GPU to prevent Metal compilation hangs...\")\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "else:\n",
    "    # Re-adding the memory growth code for when GPU is enabled\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"[GPU MODE] Memory growth enabled.\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Memory growth setting failed: {e}\")\n",
    "\n",
    "# --- 1. ROBUST CUSTOM METRICS (Safe for 8GB RAM) ---\n",
    "\n",
    "SENTINEL_VALUE = 999.0\n",
    "CLASS_WEIGHTS = tf.constant([0.8, 0.2], dtype=tf.float32)\n",
    "\n",
    "def optimized_loss_fn(y_true, y_pred):\n",
    "    # Standard masking logic without complex graph dependencies\n",
    "    mask = tf.cast(tf.not_equal(y_true, SENTINEL_VALUE), tf.float32)\n",
    "    y_p = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "    \n",
    "    # BCE calculation\n",
    "    bce = - (y_true * tf.math.log(y_p) + (1.0 - y_true) * tf.math.log(1.0 - y_p))\n",
    "    \n",
    "    # Weighting logic\n",
    "    y_true_int = tf.cast(tf.squeeze(y_true, axis=-1), tf.int32)\n",
    "    y_true_clipped = tf.clip_by_value(y_true_int, 0, 1)\n",
    "    weights = tf.gather(CLASS_WEIGHTS, y_true_clipped)\n",
    "    weights = tf.expand_dims(weights, axis=-1)\n",
    "    \n",
    "    return tf.reduce_sum(bce * weights * mask) / (tf.reduce_sum(mask) + 1e-7)\n",
    "\n",
    "def optimized_f1_class0(y_true, y_pred):\n",
    "    # Minimalist F1 logic to prevent M2 graph tracing hangs\n",
    "    mask = tf.cast(tf.not_equal(y_true, SENTINEL_VALUE), tf.float32)\n",
    "    y_t = (1.0 - y_true) * mask\n",
    "    y_p = (1.0 - tf.math.round(y_pred)) * mask\n",
    "    \n",
    "    tp = tf.reduce_sum(y_t * y_p)\n",
    "    fp = tf.reduce_sum((1.0 - y_t) * y_p * mask)\n",
    "    fn = tf.reduce_sum(y_t * (1.0 - y_p) * mask)\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall = tp / (tp + fn + 1e-7)\n",
    "    return 2 * ((precision * recall) / (precision + recall + 1e-7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aff18a",
   "metadata": {},
   "source": [
    "### Chunked GTCN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805feda",
   "metadata": {},
   "source": [
    "Define the model ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7709b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Masking, Conv1D, TimeDistributed, Dense, Dropout, Activation, Input, multiply\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "L_CHUNK = 3967 # Input sequence length (must match chunk size from data_prep)\n",
    "NUM_FEATURES = n_feature_cols\n",
    "CONV_FILTERS = 8 # Ultra-low filters for 2.67 GB cache\n",
    "KERNEL_SIZE = 32 \n",
    "N_TRAIN = 10 \n",
    "NUM_CHUNKS = 4\n",
    "\n",
    "def gated_conv_block(x, dilation_rate, filters, kernel_size):\n",
    "    conv_a = Conv1D(filters=filters, kernel_size=kernel_size, padding='causal', dilation_rate=dilation_rate, activation=None)(x)\n",
    "    conv_b = Conv1D(filters=filters, kernel_size=kernel_size, padding='causal', dilation_rate=dilation_rate, activation='sigmoid')(x)\n",
    "    gated = multiply([conv_a, conv_b])\n",
    "    return Activation('relu')(gated)\n",
    "\n",
    "inputs = Input(shape=(L_CHUNK, NUM_FEATURES))\n",
    "x = Masking(mask_value=SENTINEL_VALUE)(inputs)\n",
    "x = Conv1D(filters=CONV_FILTERS, kernel_size=KERNEL_SIZE, padding='causal', activation='relu')(x)\n",
    "\n",
    "x = gated_conv_block(x, dilation_rate=2, filters=CONV_FILTERS, kernel_size=2)\n",
    "x = gated_conv_block(x, dilation_rate=4, filters=CONV_FILTERS, kernel_size=2)\n",
    "x = gated_conv_block(x, dilation_rate=8, filters=CONV_FILTERS, kernel_size=2)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = TimeDistributed(Dense(1, activation='sigmoid'))(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a52651",
   "metadata": {},
   "source": [
    "Compile the model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e4268ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Model compiled successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,416</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m68\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m68\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │     \u001b[38;5;34m17,416\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m136\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m136\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m136\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m136\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m136\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m136\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3967\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m9\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,241</span> (71.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,241\u001b[0m (71.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,241</span> (71.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,241\u001b[0m (71.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"Initializing model weights...\")\n",
    "# _ = model(X_train_tensor[0])\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "# model.compile(\n",
    "#     optimizer='adam', \n",
    "#     loss=custom_masked_bce, \n",
    "#     metrics=[masked_f1_class0] \n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=optimized_loss_fn,\n",
    "    metrics=[optimized_f1_class0],\n",
    "    jit_compile=False \n",
    ")\n",
    "print(\"Model compiled successfully.\")\n",
    "\n",
    "# X_train_tensor = tf.cast(X_train_chunked, tf.float32)\n",
    "# Y_train_tensor = tf.cast(Y_train_chunked, tf.float32)\n",
    "# X_val_tensor = tf.cast(X_test_chunked, tf.float32)\n",
    "# Y_val_tensor = tf.cast(Y_test_chunked, tf.float32)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c33ea",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c4771d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bartenderradiatorapplied@timestudy_com',\n",
       " 'brinkaminounframed@timestudy_com',\n",
       " 'defilinganywayimmovable@timestudy_com',\n",
       " 'headwearskirmishantidote@timestudy_com',\n",
       " 'pettytransfixedsolubly@timestudy_com',\n",
       " 'remoldexcludingaffair@timestudy_com',\n",
       " 'retrialgraftedsturdy@timestudy_com',\n",
       " 'superiorpassablecosmic@timestudy_com',\n",
       " 'urchinvariablytrend@timestudy_com',\n",
       " 'washboardceramicsenticing@timestudy_com']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e9708",
   "metadata": {},
   "source": [
    "[SKIP] Only epoch training [Skip for now]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fd2100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Chunked Training (Processing 4 Chunks per User)...\n",
      "Epoch: 0\n",
      "Training on: bartenderradiatorapplied@timestudy_com\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m Y_batch = np.expand_dims(Y_chunk, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Train and get loss/metrics [loss, f1]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Accumulate ONLY the loss (index 0) and the metric (index 1)\u001b[39;00m\n\u001b[32m     30\u001b[39m epoch_loss += history[\u001b[32m0\u001b[39m] \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:629\u001b[39m, in \u001b[36mTensorFlowTrainer.train_on_batch\u001b[39m\u001b[34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdata\u001b[39m():\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m logs = tree.map_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np.array(x), logs)\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:249\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    247\u001b[39m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps_per_execution), iterator\n\u001b[32m    248\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m         outputs = \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:125\u001b[39m, in \u001b[36mTensorFlowTrainer._autoconvert_optionals.<locals>.wrapper\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(step_func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(data):\n\u001b[32m    119\u001b[39m     converted_data = tree.map_structure(\n\u001b[32m    120\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m i: (\n\u001b[32m    121\u001b[39m             \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, tf.experimental.Optional) \u001b[38;5;28;01melse\u001b[39;00m i\n\u001b[32m    122\u001b[39m         ),\n\u001b[32m    123\u001b[39m         data,\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     result = \u001b[43mstep_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1056\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1058\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1063\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:134\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_step_on_data\u001b[39m(data):\n\u001b[32m    133\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     outputs = reduce_per_replica(\n\u001b[32m    136\u001b[39m         outputs,\n\u001b[32m    137\u001b[39m         \u001b[38;5;28mself\u001b[39m.distribute_strategy,\n\u001b[32m    138\u001b[39m         reduction=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[39m, in \u001b[36mStrategyBase.run\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope():\n\u001b[32m   1669\u001b[39m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m   fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extended\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[39m, in \u001b[36mStrategyExtendedV1.call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3261\u001b[39m   kwargs = {}\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[39m, in \u001b[36m_DefaultDistributionExtended._call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:59\u001b[39m, in \u001b[36mTensorFlowTrainer.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m         y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     61\u001b[39m         y_pred = \u001b[38;5;28mself\u001b[39m(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/ops/operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/models/functional.py:183\u001b[39m, in \u001b[36mFunctional.call\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m             backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/ops/function.py:206\u001b[39m, in \u001b[36mFunction._run_through_graph\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    204\u001b[39m     operation = \u001b[38;5;28mself\u001b[39m._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     outputs = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/models/functional.py:644\u001b[39m, in \u001b[36moperation_fn.<locals>.call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    639\u001b[39m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(operation, \u001b[33m\"\u001b[39m\u001b[33m_call_context_args\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    640\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m     ):\n\u001b[32m    642\u001b[39m         kwargs[name] = value\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/ops/operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/rnn/time_distributed.py:126\u001b[39m, in \u001b[36mTimeDistributed.call\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Implementation #1: is the time axis is static, use a Python for loop.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs.shape[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    125\u001b[39m     outputs = ops.stack(\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         \u001b[43m[\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m time_distributed_transpose(outputs)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Implementation #2: use backend.vectorized_map.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/rnn/time_distributed.py:126\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Implementation #1: is the time axis is static, use a Python for loop.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs.shape[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    125\u001b[39m     outputs = ops.stack(\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         [\u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(inputs.shape[\u001b[32m0\u001b[39m])]\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m time_distributed_transpose(outputs)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Implementation #2: use backend.vectorized_map.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/rnn/time_distributed.py:120\u001b[39m, in \u001b[36mTimeDistributed.call.<locals>.step_function\u001b[39m\u001b[34m(i)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layer._call_has_training_arg:\n\u001b[32m    119\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m] = training\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layer.call(\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/ops/tensor_getitem_override.py:256\u001b[39m, in \u001b[36m_slice_helper\u001b[39m\u001b[34m(tensor, slice_spec, var)\u001b[39m\n\u001b[32m    254\u001b[39m   var_empty = constant_op.constant([], dtype=dtypes.int32)\n\u001b[32m    255\u001b[39m   packed_begin = packed_end = packed_strides = var_empty\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:1096\u001b[39m, in \u001b[36mstrided_slice\u001b[39m\u001b[34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1094\u001b[39m   strides = ones_like(begin)\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m op = \u001b[43mgen_array_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1108\u001b[39m parent_name = name\n\u001b[32m   1110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/ops/gen_array_ops.py:10964\u001b[39m, in \u001b[36mstrided_slice\u001b[39m\u001b[34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[39m\n\u001b[32m  10962\u001b[39m   shrink_axis_mask = \u001b[32m0\u001b[39m\n\u001b[32m  10963\u001b[39m shrink_axis_mask = _execute.make_int(shrink_axis_mask, \u001b[33m\"\u001b[39m\u001b[33mshrink_axis_mask\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m> \u001b[39m\u001b[32m10964\u001b[39m _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10965\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStridedSlice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10966\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10967\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10968\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10969\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10970\u001b[39m _result = _outputs[:]\n\u001b[32m  10971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:791\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    787\u001b[39m   _CheckAllInputsUsed(op_type_name, keywords)\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# NOTE(mrry): We add an explicit colocation constraint between\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;66;03m# the newly created op and any of its reference-typed inputs.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m must_colocate_inputs = [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    792\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m arg.is_ref]\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[32m    794\u001b[39m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[32m    795\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    796\u001b[39m   op = g._create_op_internal(op_type_name, inputs, dtypes=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    797\u001b[39m                              name=scope, input_types=input_types,\n\u001b[32m    798\u001b[39m                              attrs=attr_protos, op_def=op_def)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "print(\"\\nStarting Chunked Training (Processing 4 Chunks per User)...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    epoch_loss = 0.0\n",
    "    epoch_f1 = 0.0\n",
    "    total_chunks = 0\n",
    "    \n",
    "    for user_idx in range(N_TRAIN):\n",
    "        \n",
    "        current_id = train_user_ids[user_idx]\n",
    "        print('Training on: ' + str(current_id))\n",
    "        \n",
    "        for chunk_idx in range(NUM_CHUNKS):\n",
    "            \n",
    "            # Extract the single, memory-safe chunk\n",
    "            X_chunk = X_train_chunked[user_idx, chunk_idx, :, :]\n",
    "            Y_chunk = Y_train_chunked[user_idx, chunk_idx, :, :]\n",
    "            \n",
    "            # Add a batch dimension\n",
    "            X_batch = np.expand_dims(X_chunk, axis=0)\n",
    "            Y_batch = np.expand_dims(Y_chunk, axis=0)\n",
    "            \n",
    "            # Train and get loss/metrics [loss, f1]\n",
    "            history = model.train_on_batch(X_batch, Y_batch)\n",
    "            \n",
    "            # Accumulate ONLY the loss (index 0) and the metric (index 1)\n",
    "            epoch_loss += history[0] \n",
    "            epoch_f1 += history[1]\n",
    "            total_chunks += 1\n",
    "\n",
    "    avg_loss = epoch_loss / total_chunks\n",
    "    avg_f1 = epoch_f1 / total_chunks\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}: Avg Loss = {avg_loss:.4f} | Avg F1 = {avg_f1:.4f}\")\n",
    "    actual_per_step_loss = avg_loss / L_CHUNK\n",
    "    print(f\"Epoch {epoch + 1}: Per-Step Loss = {actual_per_step_loss:.4f} | Total Chunk Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42246918",
   "metadata": {},
   "source": [
    "[SKIP] Alternative, training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Chunked Training and Validation...\n",
      "\n",
      "--- Epoch 1/20 ---\n",
      "Training in progress ...\n",
      "Training: bartenderradiatorapplied@timestudy_com\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "EPOCHS = 20\n",
    "N_TRAIN = 10\n",
    "N_VAL = 90\n",
    "NUM_CHUNKS = 4\n",
    "\n",
    "print(\"\\nStarting Chunked Training and Validation...\")\n",
    "\n",
    "history_log = {\n",
    "    'train_loss': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "best_val_f1 = -1.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n",
    "    \n",
    "    # --- Phase A: Training (10 Users) ---\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_train_f1 = 0.0\n",
    "    total_train_chunks = 0\n",
    "    t_loss = 0.0\n",
    "    t_f1 = 0.0\n",
    "    print(\"Training in progress ...\")\n",
    "    \n",
    "    for u in range(N_TRAIN):\n",
    "        current_id = train_user_ids[u]\n",
    "        print(\"Training: \" + current_id)\n",
    "        # We explicitly cast to float32 here as well to be safe before feeding the GPU\n",
    "        # FIX: Convert to Tensor explicitly and ensure correct shape (Batch, Length, Features)\n",
    "        X_batch = tf.convert_to_tensor(X_train_chunked[u, :, :, :], dtype=tf.float32)\n",
    "        Y_batch = tf.convert_to_tensor(Y_train_chunked[u, :, :, :], dtype=tf.float32)\n",
    "        \n",
    "        res = model.train_on_batch(x=X_train_tensor[u], y=Y_train_tensor[u], return_dict=True)\n",
    "        t_loss += float(res.get('loss', 0))\n",
    "        t_f1 += float(res.get('masked_f1_class0', 0))\n",
    "        gc.collect()\n",
    "\n",
    "    # --- Phase B: Validation (90 Users) ---\n",
    "    epoch_val_loss = 0.0\n",
    "    epoch_val_f1 = 0.0\n",
    "    total_val_chunks = 0\n",
    "    v_loss = 0.0\n",
    "    v_f1 = 0.0\n",
    "    print(\"Validation in progress ...\")\n",
    "    \n",
    "    for u in range(N_VAL):\n",
    "        X_batch = X_test_chunked[u, :, :, :].astype(np.float32)\n",
    "        Y_batch = Y_test_chunked[u, :, :, :].astype(np.float32)\n",
    "        \n",
    "        res = model.test_on_batch(x=X_val_tensor[u], y=Y_val_tensor[u])\n",
    "        v_loss += float(res.get('loss', 0))\n",
    "        v_f1 += float(res.get('masked_f1_class0', 0))\n",
    "        if u % 20 == 0: gc.collect()\n",
    "\n",
    "    # --- Final Averages and Logging ---\n",
    "    # avg_train_loss = epoch_train_loss / total_train_chunks\n",
    "    # avg_train_f1 = epoch_train_f1 / total_train_chunks\n",
    "    # avg_val_loss = epoch_val_loss / total_val_chunks\n",
    "    # avg_val_f1 = epoch_val_f1 / total_val_chunks\n",
    "\n",
    "    # Metrics Averages\n",
    "    avg_train_loss, avg_train_f1 = t_loss / N_TRAIN, t_f1 / N_TRAIN\n",
    "    avg_val_loss, avg_val_f1 = v_loss / N_VAL, v_f1 / N_VAL\n",
    "\n",
    "    # Record to History Object\n",
    "    history_log['train_loss'].append(avg_train_loss)\n",
    "    history_log['train_f1'].append(avg_train_f1)\n",
    "    history_log['val_loss'].append(avg_val_loss)\n",
    "    history_log['val_f1'].append(avg_val_f1)\n",
    "    \n",
    "    print(f\"TRAIN | Avg Loss: {avg_train_loss:.4f} | Avg F1 (C0): {avg_train_f1:.4f}\")\n",
    "    print(f\"VAL   | Avg Loss: {avg_val_loss:.4f} | Avg F1 (C0): {avg_val_f1:.4f}\")\n",
    "    \n",
    "    actual_per_step_train_loss = avg_train_loss / L_CHUNK\n",
    "    print(f\"Per-Step Train Loss: {actual_per_step_train_loss:.6f}\")\n",
    "\n",
    "    # --- 4. CHECKPOINTING: Save best model based on Validation F1 ---\n",
    "    if avg_val_f1 > best_val_f1:\n",
    "        print(f\"!!! New Best Val F1: {avg_val_f1:.4f} - Saving weights to 'best_gtcn_model.h5'\")\n",
    "        best_val_f1 = avg_val_f1\n",
    "        model.save('best_gtcn_model.h5')\n",
    "\n",
    "# Final save of the history for external visualization scripts\n",
    "with open('/Users/adityaponnada/Downloads/time_study_data/training_history.json', 'w') as f:\n",
    "    json.dump(history_log, f)\n",
    "\n",
    "print(\"\\nLoop Complete. Best Validation F1 achieved: \", best_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33a9d235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SAFE MODE] Training on 10 users | Validating on 90 users\n",
      "Memory Strategy: Just-in-Time Tensor conversion (CPU -> GPU)\n",
      "\n",
      "--- Epoch 1/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 86.0s | Train F1: 0.3705 | Val F1: 0.3230\n",
      "!!! Saving Best Model (F1: 0.3230)\n",
      "\n",
      "--- Epoch 2/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 20.5s | Train F1: 0.3323 | Val F1: 0.3287\n",
      "!!! Saving Best Model (F1: 0.3287)\n",
      "\n",
      "--- Epoch 3/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 20.6s | Train F1: 0.3313 | Val F1: 0.3293\n",
      "!!! Saving Best Model (F1: 0.3293)\n",
      "\n",
      "--- Epoch 4/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 21.0s | Train F1: 0.3309 | Val F1: 0.3296\n",
      "!!! Saving Best Model (F1: 0.3296)\n",
      "\n",
      "--- Epoch 5/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 20.8s | Train F1: 0.3307 | Val F1: 0.3304\n",
      "!!! Saving Best Model (F1: 0.3304)\n",
      "\n",
      "--- Epoch 6/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 22.4s | Train F1: 0.3317 | Val F1: 0.3317\n",
      "!!! Saving Best Model (F1: 0.3317)\n",
      "\n",
      "--- Epoch 7/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 359.0s | Train F1: 0.3330 | Val F1: 0.3332\n",
      "!!! Saving Best Model (F1: 0.3332)\n",
      "\n",
      "--- Epoch 8/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 20.9s | Train F1: 0.3344 | Val F1: 0.3347\n",
      "!!! Saving Best Model (F1: 0.3347)\n",
      "\n",
      "--- Epoch 9/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 19.5s | Train F1: 0.3359 | Val F1: 0.3362\n",
      "!!! Saving Best Model (F1: 0.3362)\n",
      "\n",
      "--- Epoch 10/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 18.2s | Train F1: 0.3374 | Val F1: 0.3381\n",
      "!!! Saving Best Model (F1: 0.3381)\n",
      "\n",
      "--- Epoch 11/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 21.6s | Train F1: 0.3397 | Val F1: 0.3406\n",
      "!!! Saving Best Model (F1: 0.3406)\n",
      "\n",
      "--- Epoch 12/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 22.1s | Train F1: 0.3423 | Val F1: 0.3434\n",
      "!!! Saving Best Model (F1: 0.3434)\n",
      "\n",
      "--- Epoch 13/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 22.1s | Train F1: 0.3452 | Val F1: 0.3466\n",
      "!!! Saving Best Model (F1: 0.3466)\n",
      "\n",
      "--- Epoch 14/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 80.3s | Train F1: 0.3487 | Val F1: 0.3500\n",
      "!!! Saving Best Model (F1: 0.3500)\n",
      "\n",
      "--- Epoch 15/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 22.5s | Train F1: 0.3520 | Val F1: 0.3532\n",
      "!!! Saving Best Model (F1: 0.3532)\n",
      "\n",
      "--- Epoch 16/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 21.7s | Train F1: 0.3551 | Val F1: 0.3562\n",
      "!!! Saving Best Model (F1: 0.3562)\n",
      "\n",
      "--- Epoch 17/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 21.9s | Train F1: 0.3579 | Val F1: 0.3591\n",
      "!!! Saving Best Model (F1: 0.3591)\n",
      "\n",
      "--- Epoch 18/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 21.9s | Train F1: 0.3609 | Val F1: 0.3620\n",
      "!!! Saving Best Model (F1: 0.3620)\n",
      "\n",
      "--- Epoch 19/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 21.8s | Train F1: 0.3636 | Val F1: 0.3646\n",
      "!!! Saving Best Model (F1: 0.3646)\n",
      "\n",
      "--- Epoch 20/20 ---\n",
      "Training ...\n",
      "..........Validation ...\n",
      "-------- Validation starts -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE | Time: 23.7s | Train F1: 0.3662 | Val F1: 0.3671\n",
      "!!! Saving Best Model (F1: 0.3671)\n",
      "\n",
      "Training Complete.\n"
     ]
    }
   ],
   "source": [
    "history_log = {'train_loss': [], 'train_f1': [], 'val_loss': [], 'val_f1': []}\n",
    "best_val_f1 = -1.0\n",
    "EPOCHS = 20\n",
    "N_TRAIN, N_VAL = 10, 90\n",
    "L_CHUNK = 3967\n",
    "\n",
    "print(f\"\\n[SAFE MODE] Training on {N_TRAIN} users | Validating on {N_VAL} users\")\n",
    "print(\"Memory Strategy: Just-in-Time Tensor conversion (CPU -> GPU)\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n",
    "    \n",
    "    # --- Phase A: Training ---\n",
    "    print(\"Training ...\")\n",
    "    t_loss, t_f1 = 0.0, 0.0\n",
    "    for u in range(N_TRAIN):\n",
    "        # c_id = train_user_ids[u]\n",
    "        # print(\"Training for: \" + c_id)\n",
    "        # Convert ONLY the current user to a Tensor (avoids RAM overflow)\n",
    "        X_u = tf.convert_to_tensor(X_train_chunked[u], dtype=tf.float32)\n",
    "        Y_u = tf.convert_to_tensor(Y_train_chunked[u], dtype=tf.float32)\n",
    "        \n",
    "        res = model.train_on_batch(x=X_u, y=Y_u, return_dict=True)\n",
    "        t_loss += float(res['loss'])\n",
    "        t_f1 += float(res['optimized_f1_class0'])\n",
    "        print(\".\", end=\"\", flush=True) # Progress dots\n",
    "        \n",
    "        # Immediate cleanup of the user tensor\n",
    "        del X_u, Y_u\n",
    "        if u % 2 == 0: gc.collect()\n",
    "\n",
    "    # --- Phase B: Validation ---\n",
    "    print(\"Validation ...\")\n",
    "    v_loss, v_f1 = 0.0, 0.0\n",
    "    print(\"-------- Validation starts -----------\")\n",
    "    for u in range(N_VAL):\n",
    "        X_u = tf.convert_to_tensor(X_test_chunked[u], dtype=tf.float32)\n",
    "        Y_u = tf.convert_to_tensor(Y_test_chunked[u], dtype=tf.float32)\n",
    "        \n",
    "        res = model.test_on_batch(x=X_u, y=Y_u, return_dict=True)\n",
    "        v_loss += float(res['loss'])\n",
    "        v_f1 += float(res['optimized_f1_class0'])\n",
    "        \n",
    "        del X_u, Y_u\n",
    "        if u % 10 == 0: gc.collect()\n",
    "\n",
    "    # Calculate Averages\n",
    "    avg_t_f, avg_v_f = t_f1 / N_TRAIN, v_f1 / N_VAL\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"DONE | Time: {duration:.1f}s | Train F1: {avg_t_f:.4f} | Val F1: {avg_v_f:.4f}\")\n",
    "\n",
    "    # Checkpointing\n",
    "    if avg_v_f > best_val_f1:\n",
    "        best_val_f1 = avg_v_f\n",
    "        print(f\"!!! Saving Best Model (F1: {best_val_f1:.4f})\")\n",
    "        model.save('best_model_safe.h5')\n",
    "\n",
    "    # History\n",
    "    history_log['train_f1'].append(avg_t_f)\n",
    "    history_log['val_f1'].append(avg_v_f)\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "# Final save of the history for external visualization scripts\n",
    "with open('/Users/adityaponnada/Downloads/time_study_data/training_history.json', 'w') as f:\n",
    "    json.dump(history_log, f)\n",
    "print(\"\\nTraining Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8228a",
   "metadata": {},
   "source": [
    "### Model tuning and diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbe25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaponnada/Documents/codework/real_time_prompting/real_time_prompting/tfpy/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for validation set...\n",
      "\n",
      "Optimal Threshold for Class 0: 0.3123\n",
      "Max Validation F1 (C0) at this threshold: 0.5104\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. VISUALIZE TRAINING HISTORY ---\n",
    "def plot_learning_curves(history_path='/Users/adityaponnada/Downloads/time_study_data/training_history.json'):\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    epochs = range(1, len(history['train_f1']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # F1 Score Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_f1'], 'o-', label='Train F1 (C0)')\n",
    "    plt.plot(epochs, history['val_f1'], 's-', label='Val F1 (C0)')\n",
    "    plt.title('Minority Class (C0) F1-Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # We didn't save loss in the last safe-loop, but if you have it:\n",
    "    # if 'train_loss' in history:\n",
    "    #     plt.subplot(1, 2, 2)\n",
    "    #     # plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
    "    #     plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
    "    #     plt.title('Model Loss')\n",
    "    #     plt.xlabel('Epoch')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 2. FIND OPTIMAL THRESHOLD (On Validation Set) ---\n",
    "\n",
    "def plot_f1_vs_threshold(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Visualizes how the F1-score changes across different thresholds \n",
    "    specifically for the Minority Class (Class 0).\n",
    "    \"\"\"\n",
    "    # We want F1 for Class 0, so we invert the probabilities \n",
    "    # because precision_recall_curve treats the input as the 'positive' class\n",
    "    precision, recall, thresholds = precision_recall_curve(1.0 - y_true, 1.0 - y_probs)\n",
    "    \n",
    "    # Calculate F1 for each threshold\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "    \n",
    "    # Find max F1 for annotation\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    max_f1 = f1_scores[best_idx]\n",
    "    # Convert Class 0 threshold back to original model probability scale (Class 1)\n",
    "    best_thresh_orig = 1.0 - thresholds[best_idx] \n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    # Thresholds array is 1 shorter than precision/recall\n",
    "    plt.plot(thresholds, f1_scores[:-1], color='darkorange', lw=2, label='F1 Score (Class 0)')\n",
    "    \n",
    "    # Vertical line for the best threshold\n",
    "    plt.axvline(thresholds[best_idx], color='red', linestyle='--', alpha=0.6)\n",
    "    plt.scatter(thresholds[best_idx], max_f1, color='red', zorder=5)\n",
    "    \n",
    "    plt.annotate(f'Max F1: {max_f1:.4f}\\nThresh: {best_thresh_orig:.4f}', \n",
    "                 xy=(thresholds[best_idx], max_f1), \n",
    "                 xytext=(thresholds[best_idx] + 0.05, max_f1 - 0.1),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=5))\n",
    "\n",
    "    plt.title('F1-Score vs. Threshold (Class 0 Focus)')\n",
    "    plt.xlabel('Threshold for Class 0 (Probability of Non-Response)')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def find_optimal_threshold(model, X_val, Y_val):\n",
    "    \"\"\"\n",
    "    Predicts on validation users and finds the threshold that \n",
    "    maximizes the F1-score for Class 0.\n",
    "    \"\"\"\n",
    "    all_probs = []\n",
    "    all_true = []\n",
    "    \n",
    "    print(\"Generating predictions for validation set...\")\n",
    "    for u in range(len(X_val)):\n",
    "        # Predict on chunks\n",
    "        probs = model.predict(X_val[u], verbose=0)\n",
    "        \n",
    "        # Flatten and mask out sentinel values (999.0)\n",
    "        y_true = Y_val[u].flatten()\n",
    "        y_prob = probs.flatten()\n",
    "        \n",
    "        mask = y_true != 999.0\n",
    "        all_true.extend(y_true[mask])\n",
    "        all_probs.extend(y_prob[mask])\n",
    "    \n",
    "    all_true = np.array(all_true)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # We want F1 for Class 0, so we invert the probabilities\n",
    "    # because precision_recall_curve expects the 'positive' class\n",
    "    precision, recall, thresholds = precision_recall_curve(1.0 - all_true, 1.0 - all_probs)\n",
    "    \n",
    "    # Calculate F1 for each threshold\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = 1.0 - thresholds[best_idx] # Convert back to original probability scale\n",
    "    \n",
    "    print(f\"\\nOptimal Threshold for Class 0: {best_threshold:.4f}\")\n",
    "    print(f\"Max Validation F1 (C0) at this threshold: {f1_scores[best_idx]:.4f}\")\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "\n",
    "\n",
    "# --- EXECUTION FLOW ---\n",
    "# 1. Load your best model\n",
    "model = tf.keras.models.load_model('best_model_safe.h5', compile=False)\n",
    "\n",
    "# 2. Visualize\n",
    "plot_learning_curves('/Users/adityaponnada/Downloads/time_study_data/training_history.json')\n",
    "\n",
    "# 3. Tune\n",
    "opt_thresh = find_optimal_threshold(model, X_test_chunked, Y_test_chunked) # Use your 90-user val set\n",
    "\n",
    "# 4. Test\n",
    "# final_test_report(model, X_held_out, Y_held_out, threshold=opt_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8654042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. FINAL EVALUATION (On Unseen Test Set) ---\n",
    "def final_test_report(model, X_test, Y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    The 'Final Grade' script for the 30 held-out users.\n",
    "    \"\"\"\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    \n",
    "    for u in range(len(X_test)):\n",
    "        probs = model.predict(X_test[u], verbose=0)\n",
    "        y_true = Y_test[u].flatten()\n",
    "        y_prob = probs.flatten()\n",
    "        \n",
    "        mask = y_true != 999.0\n",
    "        # Classify based on tuned threshold\n",
    "        y_pred = (y_prob < threshold).astype(int) # Remember: we are targeting Class 0\n",
    "        \n",
    "        # To use standard classification_report, let's keep original 0/1 labels\n",
    "        # but the threshold logic above handles the 'avoidance' decision\n",
    "        preds = (y_prob > threshold).astype(int) \n",
    "        \n",
    "        all_true.extend(y_true[mask])\n",
    "        all_pred.extend(preds[mask])\n",
    "\n",
    "    print(\"\\n--- FINAL HELD-OUT TEST REPORT (30 USERS) ---\")\n",
    "    print(classification_report(all_true, all_pred, target_names=['Non-Response (C0)', 'Response (C1)']))\n",
    "    \n",
    "    # Confusion Matrix Visualization\n",
    "    cm = confusion_matrix(all_true, all_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Final Confusion Matrix')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
